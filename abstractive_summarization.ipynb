{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "abstractive_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f81f7d06a57649e1ab9c69cca8b2d570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6dab8218c8142009af4f85d4d712875",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56f3046102894a0e9ba3c1f7b755e7c7",
              "IPY_MODEL_6652120cd16449fca696c68e1af78928"
            ]
          }
        },
        "d6dab8218c8142009af4f85d4d712875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56f3046102894a0e9ba3c1f7b755e7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bf11e04311a4b7aa17f74ea6d55a0b3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d91b9f81bbde467996cee4b42572225f"
          }
        },
        "6652120cd16449fca696c68e1af78928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8d5641033764bb2b8f1e14eab3d6c46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 460B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d845d9997db465b89430bb421b9e1ae"
          }
        },
        "0bf11e04311a4b7aa17f74ea6d55a0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d91b9f81bbde467996cee4b42572225f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8d5641033764bb2b8f1e14eab3d6c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d845d9997db465b89430bb421b9e1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc0b15112f4540639020c1066fbecbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c2d8a8c6cd024af9ae1eeeb926757b5b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca62ba232ffa4cfba54f2dbd51e6d8a8",
              "IPY_MODEL_b58b1de516a64616966cef5a5af1946e"
            ]
          }
        },
        "c2d8a8c6cd024af9ae1eeeb926757b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca62ba232ffa4cfba54f2dbd51e6d8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f3257dbf8c694fa8b4a2c0ec0a549b7d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d87222658f3f491b98ac0dbec598a1a4"
          }
        },
        "b58b1de516a64616966cef5a5af1946e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bd2e9a368734f37937aad530be55983",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 632kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a030b3639c4247268ce2685f58dc3807"
          }
        },
        "f3257dbf8c694fa8b4a2c0ec0a549b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d87222658f3f491b98ac0dbec598a1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bd2e9a368734f37937aad530be55983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a030b3639c4247268ce2685f58dc3807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c3f6907e38c49f48c3c1ef1e4435e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34460349d5d942e59aee78558f33c2a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e27845e12d4449c881a8ee3ea271f73b",
              "IPY_MODEL_3d91540cadaf4bdca4de0ac70e30a79a"
            ]
          }
        },
        "34460349d5d942e59aee78558f33c2a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e27845e12d4449c881a8ee3ea271f73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_165d5c36e041416f9822167f5b542551",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fd80f6215c64b779c3c912f1f9f31fe"
          }
        },
        "3d91540cadaf4bdca4de0ac70e30a79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce5eb85a03df451da889afdd8f7a5680",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 73.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92bc5a96c06f4d53b1a81347943e9db7"
          }
        },
        "165d5c36e041416f9822167f5b542551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fd80f6215c64b779c3c912f1f9f31fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce5eb85a03df451da889afdd8f7a5680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92bc5a96c06f4d53b1a81347943e9db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5383faa4ec554dc59c34be02a9bd6edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_667efa312a014b2dbc738089f6e72cf8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d7a1148a74a1462d92143d32bf5454b6",
              "IPY_MODEL_126a92be2f2547d2b646d79d7949da4d"
            ]
          }
        },
        "667efa312a014b2dbc738089f6e72cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7a1148a74a1462d92143d32bf5454b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3476b959f292498685ad05a48372532f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f6e7b1a44864485b0b2d2f00b1db729"
          }
        },
        "126a92be2f2547d2b646d79d7949da4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e104a552657e4363be4db85046bba639",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:21&lt;00:00, 25.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ce29b08b64541648d352d117191139c"
          }
        },
        "3476b959f292498685ad05a48372532f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f6e7b1a44864485b0b2d2f00b1db729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e104a552657e4363be4db85046bba639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ce29b08b64541648d352d117191139c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f00a6a57e5b948ba848cab5166f4f2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0872e34b66f84af199feebe7849332a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09180cfa47b94eee937d299e916b3dab",
              "IPY_MODEL_458fa919d1464af6b581d39d518bcda8"
            ]
          }
        },
        "0872e34b66f84af199feebe7849332a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09180cfa47b94eee937d299e916b3dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c261e458b67540868f0c620b8ccbcccb",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff6828c794e341f4bc50d6634ae14450"
          }
        },
        "458fa919d1464af6b581d39d518bcda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f87a4f82dd5b41c68ab96981cb35dac1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [01:21&lt;00:00, 16.36s/ url]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c90977e1741b418da92d1801db975591"
          }
        },
        "c261e458b67540868f0c620b8ccbcccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff6828c794e341f4bc50d6634ae14450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f87a4f82dd5b41c68ab96981cb35dac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c90977e1741b418da92d1801db975591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "281518474371424e875f331014302374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e4c9973213d4f95ad700a9a5510bba1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a3ca4f488f948dbbe76bf092c39361c",
              "IPY_MODEL_07ffe8376cb94d83ae4e50682a257206"
            ]
          }
        },
        "9e4c9973213d4f95ad700a9a5510bba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a3ca4f488f948dbbe76bf092c39361c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0700b07436874fcdb976cbd507a9109c",
            "_dom_classes": [],
            "description": "Dl Size...: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d411ae76b644292855437dbea7f425d"
          }
        },
        "07ffe8376cb94d83ae4e50682a257206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b30a6f466c1d4fd3aef50bdfdcfcf36f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 557/? [01:21&lt;00:00,  6.81 MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b09d6fa1e100482a818eb9853f93b04a"
          }
        },
        "0700b07436874fcdb976cbd507a9109c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d411ae76b644292855437dbea7f425d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b30a6f466c1d4fd3aef50bdfdcfcf36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b09d6fa1e100482a818eb9853f93b04a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dafd58b314254a36b335854bd64b4128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5803ef3bda8a4cad9bc05bad0267a366",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9d8f1474a764d889fb287fe35cbea9e",
              "IPY_MODEL_ceb64df82bd94558856fbf31fa478b61"
            ]
          }
        },
        "5803ef3bda8a4cad9bc05bad0267a366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9d8f1474a764d889fb287fe35cbea9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_750fca7237684e29ac99a0a9d5f89c30",
            "_dom_classes": [],
            "description": "Extraction completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34c4a51ef1534d54be7f9a549943f3e5"
          }
        },
        "ceb64df82bd94558856fbf31fa478b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1cd7196efbb14ddcb139d58aa8809154",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [01:21&lt;00:00, 40.87s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac70bf2ceb5e45c290830a9d8be020e0"
          }
        },
        "750fca7237684e29ac99a0a9d5f89c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34c4a51ef1534d54be7f9a549943f3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cd7196efbb14ddcb139d58aa8809154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac70bf2ceb5e45c290830a9d8be020e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c85ef6dd4dc44b29a84385dc3f755831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad758a57b829467397b753ad22b49524",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47bd0a8ff8ff42d39b613fe6c205c19f",
              "IPY_MODEL_86ccfa06cd004661a4390a4d8d2c515c"
            ]
          }
        },
        "ad758a57b829467397b753ad22b49524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47bd0a8ff8ff42d39b613fe6c205c19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a4180ddd1f7c4f48b34a1892f8531a8a",
            "_dom_classes": [],
            "description": "Generating splits...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c2ec00085f2476c886510cc883112ad"
          }
        },
        "86ccfa06cd004661a4390a4d8d2c515c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ea4c1cd9385456a96141469c1e9af87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [05:08&lt;00:00, 147.10s/ splits]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_409c2105b7ad491aa8aefed7fe885646"
          }
        },
        "a4180ddd1f7c4f48b34a1892f8531a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c2ec00085f2476c886510cc883112ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ea4c1cd9385456a96141469c1e9af87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "409c2105b7ad491aa8aefed7fe885646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7dfcf5e11d2a4713a6cd6e439b31610d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_81887921e0c54f1d9c5093f13e3c0f56",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_310d658613704286ae6dcb18f9720249",
              "IPY_MODEL_e5a8a759c1264c6f8738c0cd9efc0006"
            ]
          }
        },
        "81887921e0c54f1d9c5093f13e3c0f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "310d658613704286ae6dcb18f9720249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0eb7a1e7b97f432cb02765a011005144",
            "_dom_classes": [],
            "description": "Generating train examples...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 287113,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 287113,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b93aa14b35264833bdaaa26fd8ac4e23"
          }
        },
        "e5a8a759c1264c6f8738c0cd9efc0006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d9e05f63b62432da132669f2f23261d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 287113/287113 [04:45&lt;00:00, 1133.17 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e031ed028b84bb78f504a7f93a72d98"
          }
        },
        "0eb7a1e7b97f432cb02765a011005144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b93aa14b35264833bdaaa26fd8ac4e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d9e05f63b62432da132669f2f23261d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e031ed028b84bb78f504a7f93a72d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a21fb4bb66224e64a2a21018f2523d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d593271dbd3a42dc9ae38c213b3ff7f3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8031632b6a1947739c37d6c53c5918a5",
              "IPY_MODEL_c23fd5968fc74310a6720924cb230d03"
            ]
          }
        },
        "d593271dbd3a42dc9ae38c213b3ff7f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8031632b6a1947739c37d6c53c5918a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe1ce20396d14029be86dc2fc3593c27",
            "_dom_classes": [],
            "description": "Shuffling cnn_dailymail-train.tfrecord...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 287113,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 287113,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_106576568c1748d0b1cabfa7696465a6"
          }
        },
        "c23fd5968fc74310a6720924cb230d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57afa32e925e4101859609c6e4b9ad31",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 287113/287113 [00:06&lt;00:00, 44028.19 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be2c16068969410fa8f86a7b6426e9a7"
          }
        },
        "fe1ce20396d14029be86dc2fc3593c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "106576568c1748d0b1cabfa7696465a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57afa32e925e4101859609c6e4b9ad31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be2c16068969410fa8f86a7b6426e9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f61c55b35514d569d64b5e4c159329e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cfa9f9bb08094f2c813a323a5a8a2f6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b8beabb49464ef796318f8b561a2424",
              "IPY_MODEL_988c96adf51e473698c5d78a7c4fd4b3"
            ]
          }
        },
        "cfa9f9bb08094f2c813a323a5a8a2f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b8beabb49464ef796318f8b561a2424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b5393795fbf452f92934c2e6b3647cc",
            "_dom_classes": [],
            "description": "Generating validation examples...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 13368,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13368,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca2d1b168d5f4da8857743edc2811874"
          }
        },
        "988c96adf51e473698c5d78a7c4fd4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1616c50a2054fc78b4f164410f4ee80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13368/13368 [00:09&lt;00:00, 1505.79 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9435e7348e046c09ff43aaa70f1d858"
          }
        },
        "7b5393795fbf452f92934c2e6b3647cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca2d1b168d5f4da8857743edc2811874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1616c50a2054fc78b4f164410f4ee80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9435e7348e046c09ff43aaa70f1d858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38f2ae81e09b4dbb9051bce7db29322c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07f498909b2449adb13cf556cbd196b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d04d8b716775499c980a1e569f87beed",
              "IPY_MODEL_82f073e8391040a59f9853d0f553f908"
            ]
          }
        },
        "07f498909b2449adb13cf556cbd196b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d04d8b716775499c980a1e569f87beed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_88e334563db54f2caa33071bd95e9180",
            "_dom_classes": [],
            "description": "Shuffling cnn_dailymail-validation.tfrecord...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 13368,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13368,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f72891ef50c74cbc81ef68f32ba14fab"
          }
        },
        "82f073e8391040a59f9853d0f553f908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_282655ddf19a4fa9b2603cc99ecea0a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13368/13368 [00:00&lt;00:00, 88288.61 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18202ec720d542a187a978018a8d008f"
          }
        },
        "88e334563db54f2caa33071bd95e9180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f72891ef50c74cbc81ef68f32ba14fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "282655ddf19a4fa9b2603cc99ecea0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18202ec720d542a187a978018a8d008f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b97a1caa82fd43f6940ece471f3a354a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_02d236d5c5504d55aeda650dfb521b0c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1d11ae8d2c344f19a42b103c47bd0708",
              "IPY_MODEL_d5b31c0a42444fb8bde44d65f7364dbe"
            ]
          }
        },
        "02d236d5c5504d55aeda650dfb521b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d11ae8d2c344f19a42b103c47bd0708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_298870dfaa7445609eb49b803bceb301",
            "_dom_classes": [],
            "description": "Generating test examples...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 11490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11490,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eee8bb29437c48939c257bb793af6104"
          }
        },
        "d5b31c0a42444fb8bde44d65f7364dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45ae5fb4f3254243b5fc304d7843c461",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11490/11490 [00:07&lt;00:00, 1490.39 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3aedfc1ed22f4c138f262c371b43a93b"
          }
        },
        "298870dfaa7445609eb49b803bceb301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eee8bb29437c48939c257bb793af6104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45ae5fb4f3254243b5fc304d7843c461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3aedfc1ed22f4c138f262c371b43a93b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6b7a7400ff24db8be922193c9667ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae4a5dcfa5b144649477289fff9a70e0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c846ad445b69487c896d78a67debe7fb",
              "IPY_MODEL_f25e172fcc2e41d38ab58ee19516aed1"
            ]
          }
        },
        "ae4a5dcfa5b144649477289fff9a70e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c846ad445b69487c896d78a67debe7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_857edb26a68649948526b4188eb7ff05",
            "_dom_classes": [],
            "description": "Shuffling cnn_dailymail-test.tfrecord...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 11490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11490,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb9f3a2a5c234567b7ed4fd07980bfa3"
          }
        },
        "f25e172fcc2e41d38ab58ee19516aed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ed5070632b8147dba5513d90e36ed8e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11490/11490 [00:00&lt;00:00, 95159.18 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87611510dfa04d79bb269cfd0251e407"
          }
        },
        "857edb26a68649948526b4188eb7ff05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb9f3a2a5c234567b7ed4fd07980bfa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed5070632b8147dba5513d90e36ed8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87611510dfa04d79bb269cfd0251e407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1UdfsNaSx_Q",
        "outputId": "cd43c3ab-114a-4bbf-b93e-b3853051b857"
      },
      "source": [
        "!pip install tfds_nightly"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tfds_nightly in c:\\programdata\\anaconda3\\lib\\site-packages (4.2.0.dev202101150106)\n",
            "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (0.11.0)WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n",
            "\n",
            "Requirement already satisfied: promise in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (2.3)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (5.0.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (3.14.0)\n",
            "Requirement already satisfied: tensorflow-metadata in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (0.26.0)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (4.50.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (2.24.0)\n",
            "Requirement already satisfied: six in c:\\users\\pc\\appdata\\roaming\\python\\python38\\site-packages (from tfds_nightly) (1.15.0)\n",
            "Requirement already satisfied: dill in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (0.3.3)\n",
            "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (0.18.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (20.3.0)\n",
            "Requirement already satisfied: termcolor in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (1.1.0)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from tfds_nightly) (1.19.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tfds_nightly) (1.52.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tfds_nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tfds_nightly) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tfds_nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tfds_nightly) (2020.6.20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE07AyquToF-",
        "outputId": "17ef5136-142c-4f27-ab6c-6da1f5527ef8"
      },
      "source": [
        "!pip install transformers\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.2.0)\n",
            "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2020.10.15)\n",
            "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.19.2)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.50.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in c:\\users\\pc\\appdata\\roaming\\python\\python38\\site-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
            "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whh-SP2yUP5E",
        "outputId": "643a5435-d196-451b-b71d-5343ede33998"
      },
      "source": [
        "!pip install bert_score"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert_score in c:\\programdata\\anaconda3\\lib\\site-packages (0.3.7)\n",
            "Requirement already satisfied: torch>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from bert_score) (1.7.1)\n",
            "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from bert_score) (2.24.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from bert_score) (4.50.2)\n",
            "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from bert_score) (3.3.2)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from bert_score) (1.19.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from bert_score) (4.2.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from bert_score) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->bert_score) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->bert_score) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->bert_score) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->bert_score) (3.0.4)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (2.4.7)\n",
            "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (1.3.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (8.0.1)\n",
            "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.0.43)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert_score) (3.0.12)\n",
            "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert_score) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert_score) (2020.10.15)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.9.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2020.1)\n",
            "Requirement already satisfied: six in c:\\users\\pc\\appdata\\roaming\\python\\python38\\site-packages (from cycler>=0.10->matplotlib->bert_score) (1.15.0)\n",
            "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers>=3.0.0->bert_score) (7.1.2)\n",
            "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers>=3.0.0->bert_score) (0.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbnZYuZXUwIr",
        "outputId": "34e238b9-4306-426c-ac9a-7a6d496e22f5"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: six in c:\\users\\pc\\appdata\\roaming\\python\\python38\\site-packages (from rouge) (1.15.0)\n",
            "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyG_qbTqWcI1",
        "outputId": "723bd74d-d551-4848-9bf3-64e72f87cd97"
      },
      "source": [
        "!pip install tensor2tensor && t2t-trainer"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensor2tensor\n",
            "  Using cached tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4 MB)\n",
            "Collecting pypng\n",
            "  Using cached pypng-0.0.20.tar.gz (649 kB)\n",
            "Requirement already satisfied: tf-slim in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (1.1.0)\n",
            "Collecting gym\n",
            "  Using cached gym-0.18.0.tar.gz (1.6 MB)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (1.19.2)\n",
            "Collecting dopamine-rl\n",
            "  Using cached dopamine_rl-3.1.9-py3-none-any.whl (118 kB)\n",
            "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (8.0.1)\n",
            "Collecting bz2file\n",
            "  Using cached bz2file-0.98.tar.gz (11 kB)\n",
            "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (4.5.1.48)\n",
            "Collecting kfac\n",
            "  Using cached kfac-0.2.3-py2.py3-none-any.whl (191 kB)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (1.5.2)\n",
            "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (2.10.0)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (4.50.2)\n",
            "Collecting gunicorn\n",
            "  Using cached gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
            "Requirement already satisfied: flask in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (1.1.2)\n",
            "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (1.6.2)\n",
            "Requirement already satisfied: tensorflow-addons in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (0.12.0)\n",
            "Collecting tensorflow-probability==0.7.0\n",
            "  Using cached tensorflow_probability-0.7.0-py2.py3-none-any.whl (981 kB)\n",
            "Requirement already satisfied: gevent in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (20.9.0)\n",
            "Collecting tensorflow-gan\n",
            "  Using cached tensorflow_gan-2.0.0-py2.py3-none-any.whl (365 kB)\n",
            "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (0.11.0)\n",
            "Collecting mesh-tensorflow\n",
            "  Using cached mesh_tensorflow-0.1.18-py3-none-any.whl (361 kB)\n",
            "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (2.24.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\pc\\appdata\\roaming\\python\\python38\\site-packages (from tensor2tensor) (1.15.0)\n",
            "ERROR: Could not find a version that satisfies the requirement jaxlib>=0.1.51 (from dopamine-rl->tensor2tensor) (from versions: none)\n",
            "ERROR: No matching distribution found for jaxlib>=0.1.51 (from dopamine-rl->tensor2tensor)\n",
            "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n",
            "Requirement already satisfied: google-api-python-client in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (1.12.8)\n",
            "Requirement already satisfied: oauth2client in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (4.1.3)\n",
            "Requirement already satisfied: gin-config in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (0.4.0)\n",
            "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (0.18.2)\n",
            "Requirement already satisfied: tensorflow-datasets in c:\\programdata\\anaconda3\\lib\\site-packages (from tensor2tensor) (4.2.0)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0\n",
            "  Using cached pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym->tensor2tensor) (1.6.0)\n",
            "Collecting jax>=0.1.72\n",
            "  Using cached jax-0.2.9.tar.gz (551 kB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1lkcYp-SBl8"
      },
      "source": [
        "import os\r\n",
        "# core_path = '/content/drive/MyDrive/BERT_abstractive_summarization/abstractive_summarization'\r\n",
        "core_path = os.getcwd()\r\n",
        "dataset_name = 'cnn_dailymail'\r\n",
        "vocab_path = os.path.join(core_path, 'input_files', 'vocab_files')\r\n",
        "file_path = {\r\n",
        "    'best_ckpt_path': os.path.join(core_path, 'created_files', 'training_summarization_model_ckpt', dataset_name, 'best_checkpoints'),\r\n",
        "    'ckpt_path': os.path.join(core_path, 'created_files', 'training_summarization_model_ckpt', dataset_name, 'checkpoints'),\r\n",
        "    'vocab_path': os.path.join(core_path, 'input_files', 'Vocab_files'),\r\n",
        "    'infer_csv_path': os.path.join(core_path, \"input_files/Azure_dataset/Test.csv\"),\r\n",
        "    'infer_ckpt_path': os.path.join(core_path, 'created_files', 'training_summarization_model_ckpt', dataset_name, 'infer_checkpoints'),\r\n",
        "    'log_path': os.path.join(core_path, \"created_files/tensorflow.log\"),\r\n",
        "    'tensorboard_log': os.path.join(core_path, \"created_files/tensorboard_logs/\"+dataset_name+\"/\"),\r\n",
        "    'summary_write_path': os.path.join(core_path, 'created_files', 'summaries', dataset_name),\r\n",
        "    'subword_vocab_path': os.path.join(core_path, \"input_files/vocab_file_summarization_\"+dataset_name),\r\n",
        "    'train_csv_path': os.path.join(core_path, \"input_files/Azure_dataset/Train.csv\"),\r\n",
        "    'dataset': os.path.join(core_path, 'input_files', dataset_name)\r\n",
        "}\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtN0_9zS_Oc"
      },
      "source": [
        "config = {\r\n",
        "    \r\n",
        "    'copy_gen':True,\r\n",
        "    'create_hist':False,             # create histogram of summary length and # of tokens per batch\r\n",
        "    'doc_length': 512,\r\n",
        "    'd_model': 768,                  # the projected word vector dimension\r\n",
        "    'dff': 2048,                      # feed forward network hidden parameters\r\n",
        "    'early_stop' : True,\r\n",
        "    'eval_after' : 5000,              #Run evaluation after this many samples are trained \r\n",
        "    'init_tolerance':0,\r\n",
        "    'input_vocab_size': 30522,        # total vocab size + start and end token\r\n",
        "    'last_recorded_value': None,\r\n",
        "    'monitor_metric' : 'combined_metric',\r\n",
        "    'monitor_only_after': 1,        # monitor the monitor_metric only after this epoch                                           \r\n",
        "    'max_tokens_per_line' : 1763,   # 1763 = 90 percentile  \r\n",
        "    'num_examples_to_train': None,   #If None then all the examples in the dataset will be used to train\r\n",
        "    'num_examples_to_infer': None,\r\n",
        "    'num_heads': 8,                  # the number of heads in the multi-headed attention unit\r\n",
        "    'num_layers': 8,                 # number of transformer blocks\r\n",
        "    'print_chks': 50,                # print training progress per number of batches specified\r\n",
        "    'pretrained_bert_model': 'bert-base-uncased',\r\n",
        "    'run_tensorboard': True,\r\n",
        "    'show_detokenized_samples' : False,\r\n",
        "    'summ_length': 72,\r\n",
        "    'start_from_batch':353556,\r\n",
        "    'target_vocab_size': 30522,       # total vocab size + start and end token\r\n",
        "    'test_size': 0.05,               # test set split size\r\n",
        "    'tfds_name' : 'cnn_dailymail',   # tfds dataset to be used\r\n",
        "    'tolerance_threshold': 5,        # tolerance counter used for early stopping\r\n",
        "    'use_tfds' : True,               # use tfds datasets as input to the model \r\n",
        "    'valid_samples_to_eval' : 100,\r\n",
        "    'write_per_step': 5000,            # write summary for every specified epoch\r\n",
        "    'write_summary_op': True         # write validation summary to hardisk\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "h_parms = {\r\n",
        "\t 'accumulation_steps': 36,                                                                                   \r\n",
        "\t 'batch_size': 1,\r\n",
        "\t 'beam_sizes': [2, 3, 4],        \t     # Used only during inference                                                 \r\n",
        "\t 'combined_metric_weights': [0.4, 0.3, 0.3], #(bert_score, rouge, validation accuracy)\r\n",
        "\t 'dropout_rate': 0.0,\r\n",
        "\t 'epochs': 10,\r\n",
        "\t 'epsilon_ls': 0.0,              \t     # label_smoothing hyper parameter\r\n",
        "\t 'grad_clipnorm':None,\r\n",
        "\t 'l2_norm':0,\r\n",
        "\t 'learning_rate': None,          \t     # change to None to set learning rate decay\r\n",
        "\t 'length_penalty' : 1,                       # Beam search hyps . Used only during inference                                                 \r\n",
        "\t 'mean_attention_heads':True,                # if False then the attention parameters of the last head will be used\r\n",
        "\t 'mean_parameters_of_layers':True,           # if False then the attention parameters of the last layer will be used\r\n",
        "\t 'validation_batch_size' : 8\r\n",
        "\t }"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PMlSiRiWYoo"
      },
      "source": [
        "# coding=utf-8\r\n",
        "# Copyright 2019 The Tensor2Tensor Authors.\r\n",
        "#\r\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        "# you may not use this file except in compliance with the License.\r\n",
        "# You may obtain a copy of the License at\r\n",
        "#\r\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
        "#\r\n",
        "# Unless required by applicable law or agreed to in writing, software\r\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        "# See the License for the specific language governing permissions and\r\n",
        "# limitations under the License.\r\n",
        "\r\n",
        "\"\"\"Implementation of beam search with penalties.\"\"\"\r\n",
        "\r\n",
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from tensor2tensor.layers import common_layers\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.python.ops import inplace_ops\r\n",
        "from tensorflow.python.util import nest\r\n",
        "\r\n",
        "# Assuming EOS_ID is 1\r\n",
        "EOS_ID = 1\r\n",
        "# Default value for INF\r\n",
        "INF = 1. * 1e7\r\n",
        "\r\n",
        "\r\n",
        "def _merge_beam_dim(tensor):\r\n",
        "  \"\"\"Reshapes first two dimensions in to single dimension.\r\n",
        "  Args:\r\n",
        "    tensor: Tensor to reshape of shape [A, B, ...]\r\n",
        "  Returns:\r\n",
        "    Reshaped tensor of shape [A*B, ...]\r\n",
        "  \"\"\"\r\n",
        "  shape = common_layers.shape_list(tensor)\r\n",
        "  shape[0] *= shape[1]  # batch -> batch * beam_size\r\n",
        "  shape.pop(1)  # Remove beam dim\r\n",
        "  return tf.reshape(tensor, shape)\r\n",
        "\r\n",
        "\r\n",
        "def _unmerge_beam_dim(tensor, batch_size, beam_size):\r\n",
        "  \"\"\"Reshapes first dimension back to [batch_size, beam_size].\r\n",
        "  Args:\r\n",
        "    tensor: Tensor to reshape of shape [batch_size*beam_size, ...]\r\n",
        "    batch_size: Tensor, original batch size.\r\n",
        "    beam_size: int, original beam size.\r\n",
        "  Returns:\r\n",
        "    Reshaped tensor of shape [batch_size, beam_size, ...]\r\n",
        "  \"\"\"\r\n",
        "  shape = common_layers.shape_list(tensor)\r\n",
        "  new_shape = [batch_size] + [beam_size] + shape[1:]\r\n",
        "  return tf.reshape(tensor, new_shape)\r\n",
        "\r\n",
        "\r\n",
        "def _expand_to_beam_size(tensor, beam_size):\r\n",
        "  \"\"\"Tiles a given tensor by beam_size.\r\n",
        "  Args:\r\n",
        "    tensor: tensor to tile [batch_size, ...]\r\n",
        "    beam_size: How much to tile the tensor by.\r\n",
        "  Returns:\r\n",
        "    Tiled tensor [batch_size, beam_size, ...]\r\n",
        "  \"\"\"\r\n",
        "  tensor = tf.expand_dims(tensor, axis=1)\r\n",
        "  tile_dims = [1] * tensor.shape.ndims\r\n",
        "  tile_dims[1] = beam_size\r\n",
        "\r\n",
        "  return tf.tile(tensor, tile_dims)\r\n",
        "\r\n",
        "\r\n",
        "def get_state_shape_invariants(tensor):\r\n",
        "  \"\"\"Returns the shape of the tensor but sets middle dims to None.\"\"\"\r\n",
        "  shape = tensor.shape.as_list()\r\n",
        "  for i in range(1, len(shape) - 1):\r\n",
        "    shape[i] = None\r\n",
        "  return tf.TensorShape(shape)\r\n",
        "\r\n",
        "\r\n",
        "def compute_batch_indices(batch_size, beam_size):\r\n",
        "  \"\"\"Computes the i'th coordinate that contains the batch index for gathers.\r\n",
        "  Batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which\r\n",
        "  batch the beam item is in. This will create the i of the i,j coordinate\r\n",
        "  needed for the gather.\r\n",
        "  Args:\r\n",
        "    batch_size: Batch size\r\n",
        "    beam_size: Size of the beam.\r\n",
        "  Returns:\r\n",
        "    batch_pos: [batch_size, beam_size] tensor of ids\r\n",
        "  \"\"\"\r\n",
        "  batch_pos = tf.range(batch_size * beam_size) // beam_size\r\n",
        "  batch_pos = tf.reshape(batch_pos, [batch_size, beam_size])\r\n",
        "  return batch_pos\r\n",
        "\r\n",
        "\r\n",
        "def fast_tpu_gather(params, indices, name=None):\r\n",
        "  \"\"\"Fast gather implementation for models running on TPU.\r\n",
        "  This function use one_hot and batch matmul to do gather, which is faster\r\n",
        "  than gather_nd on TPU. For params that have dtype of int32 (sequences to\r\n",
        "  gather from), batch_gather is used to keep accuracy.\r\n",
        "  Args:\r\n",
        "    params: A tensor from which to gather values.\r\n",
        "      [batch_size, original_size, ...]\r\n",
        "    indices: A tensor used as the index to gather values.\r\n",
        "      [batch_size, selected_size].\r\n",
        "    name: A string, name of the operation (optional).\r\n",
        "  Returns:\r\n",
        "    gather_result: A tensor that has the same rank as params.\r\n",
        "      [batch_size, selected_size, ...]\r\n",
        "  \"\"\"\r\n",
        "  with tf.compat.v1.name_scope(name):\r\n",
        "    dtype = params.dtype\r\n",
        "\r\n",
        "    def _gather(params, indices):\r\n",
        "      \"\"\"Fast gather using one_hot and batch matmul.\"\"\"\r\n",
        "      if dtype != tf.float32:\r\n",
        "        params = tf.cast(params, dtype=tf.float32)\r\n",
        "      shape = common_layers.shape_list(params)\r\n",
        "      indices_shape = common_layers.shape_list(indices)\r\n",
        "      ndims = params.shape.ndims\r\n",
        "      # Adjust the shape of params to match one-hot indices, which is the\r\n",
        "      # requirement of Batch MatMul.\r\n",
        "      if ndims == 2:\r\n",
        "        params = tf.expand_dims(params, axis=-1)\r\n",
        "      if ndims > 3:\r\n",
        "        params = tf.reshape(params, [shape[0], shape[1], -1])\r\n",
        "      gather_result = tf.matmul(\r\n",
        "          tf.one_hot(indices, shape[1], dtype=params.dtype), params)\r\n",
        "      if ndims == 2:\r\n",
        "        gather_result = tf.squeeze(gather_result, axis=-1)\r\n",
        "      if ndims > 3:\r\n",
        "        shape[1] = indices_shape[1]\r\n",
        "        gather_result = tf.reshape(gather_result, shape)\r\n",
        "      if dtype != tf.float32:\r\n",
        "        gather_result = tf.cast(gather_result, dtype)\r\n",
        "      return gather_result\r\n",
        "\r\n",
        "    # If the dtype is int, use the gather instead of one_hot matmul to avoid\r\n",
        "    # precision loss. The max int value can be represented by bfloat16 in MXU is\r\n",
        "    # 256, which is smaller than the possible id values. Encoding/decoding can\r\n",
        "    # potentially used to make it work, but the benenfit is small right now.\r\n",
        "    if dtype.is_integer:\r\n",
        "      gather_result = tf.compat.v1.batch_gather(params, indices)\r\n",
        "    else:\r\n",
        "      gather_result = _gather(params, indices)\r\n",
        "\r\n",
        "    return gather_result\r\n",
        "\r\n",
        "\r\n",
        "def _create_make_unique(inputs):\r\n",
        "  \"\"\"Replaces the lower bits of each element with iota.\r\n",
        "  The iota is used to derive the index, and also serves the purpose to\r\n",
        "  make each element unique to break ties.\r\n",
        "  Args:\r\n",
        "    inputs: A tensor with rank of 2 and dtype of tf.float32.\r\n",
        "      [batch_size, original_size].\r\n",
        "  Returns:\r\n",
        "    A tensor after element wise transformation, with dtype the same as inputs.\r\n",
        "    [batch_size, original_size].\r\n",
        "  Raises:\r\n",
        "    ValueError: If the rank of the input tensor does not equal 2.\r\n",
        "  \"\"\"\r\n",
        "  if inputs.shape.ndims != 2:\r\n",
        "    raise ValueError(\"Input of top_k_with_unique must be rank-2 \"\r\n",
        "                     \"but got: %s\" % inputs.shape)\r\n",
        "\r\n",
        "  height = inputs.shape[0]\r\n",
        "  width = inputs.shape[1]\r\n",
        "  zeros = tf.zeros([height, width], dtype=tf.int32)\r\n",
        "\r\n",
        "  # Count_mask is used to mask away the low order bits to ensure that every\r\n",
        "  # element is distinct.\r\n",
        "  log2_ceiling = int(math.ceil(math.log(int(width), 2)))\r\n",
        "  next_power_of_two = 1 << log2_ceiling\r\n",
        "  count_mask = ~(next_power_of_two - 1)\r\n",
        "  count_mask_r0 = tf.constant(count_mask)\r\n",
        "  count_mask_r2 = tf.fill([height, width], count_mask_r0)\r\n",
        "\r\n",
        "  # Smallest_normal is the bit representation of the smallest positive normal\r\n",
        "  # floating point number. The sign is zero, exponent is one, and the fraction\r\n",
        "  # is zero.\r\n",
        "  smallest_normal = 1 << 23\r\n",
        "  smallest_normal_r0 = tf.constant(smallest_normal, dtype=tf.int32)\r\n",
        "  smallest_normal_r2 = tf.fill([height, width], smallest_normal_r0)\r\n",
        "\r\n",
        "  # Low_bit_mask is used to mask away the sign bit when computing the absolute\r\n",
        "  # value.\r\n",
        "  low_bit_mask = ~(1 << 31)\r\n",
        "  low_bit_mask_r0 = tf.constant(low_bit_mask, dtype=tf.int32)\r\n",
        "  low_bit_mask_r2 = tf.fill([height, width], low_bit_mask_r0)\r\n",
        "\r\n",
        "  iota = tf.tile(tf.expand_dims(tf.range(width, dtype=tf.int32), 0),\r\n",
        "                 [height, 1])\r\n",
        "\r\n",
        "  # Compare the absolute value with positive zero to handle negative zero.\r\n",
        "  input_r2 = tf.bitcast(inputs, tf.int32)\r\n",
        "  abs_r2 = tf.bitwise.bitwise_and(input_r2, low_bit_mask_r2)\r\n",
        "  if_zero_r2 = tf.equal(abs_r2, zeros)\r\n",
        "  smallest_normal_preserving_sign_r2 = tf.bitwise.bitwise_or(\r\n",
        "      input_r2, smallest_normal_r2)\r\n",
        "  input_no_zeros_r2 = tf.compat.v1.where(\r\n",
        "      if_zero_r2, smallest_normal_preserving_sign_r2, input_r2)\r\n",
        "\r\n",
        "  # Discard the low-order bits and replace with iota.\r\n",
        "  and_r2 = tf.bitwise.bitwise_and(input_no_zeros_r2, count_mask_r2)\r\n",
        "  or_r2 = tf.bitwise.bitwise_or(and_r2, iota)\r\n",
        "  return tf.bitcast(or_r2, tf.float32)\r\n",
        "\r\n",
        "\r\n",
        "def _create_topk_unique(inputs, k):\r\n",
        "  \"\"\"Creates the top k values in sorted order with indices.\r\n",
        "  Args:\r\n",
        "    inputs: A tensor with rank of 2. [batch_size, original_size].\r\n",
        "    k: An integer, number of top elements to select.\r\n",
        "  Returns:\r\n",
        "    topk_r2: A tensor, the k largest elements. [batch_size, k].\r\n",
        "    topk_indices_r2: A tensor, indices of the top k values. [batch_size, k].\r\n",
        "  \"\"\"\r\n",
        "  height = inputs.shape[0]\r\n",
        "  width = inputs.shape[1]\r\n",
        "  neg_inf_r0 = tf.constant(-np.inf, dtype=tf.float32)\r\n",
        "  ones = tf.ones([height, width], dtype=tf.float32)\r\n",
        "  neg_inf_r2 = ones * neg_inf_r0\r\n",
        "  inputs = tf.compat.v1.where(tf.math.is_nan(inputs), neg_inf_r2, inputs)\r\n",
        "\r\n",
        "  # Select the current largest value k times and keep them in topk_r2. The\r\n",
        "  # selected largest values are marked as the smallest value to avoid being\r\n",
        "  # selected again.\r\n",
        "  tmp = inputs\r\n",
        "  topk_r2 = tf.zeros([height, k], dtype=tf.float32)\r\n",
        "  for i in range(k):\r\n",
        "    kth_order_statistic = tf.reduce_max(input_tensor=tmp, axis=1, keepdims=True)\r\n",
        "    k_mask = tf.tile(tf.expand_dims(tf.equal(tf.range(k), tf.fill([k], i)), 0),\r\n",
        "                     [height, 1])\r\n",
        "    topk_r2 = tf.compat.v1.where(k_mask, tf.tile(kth_order_statistic, [1, k]), topk_r2)\r\n",
        "    ge_r2 = tf.greater_equal(inputs, tf.tile(kth_order_statistic, [1, width]))\r\n",
        "    tmp = tf.compat.v1.where(ge_r2, neg_inf_r2, inputs)\r\n",
        "\r\n",
        "  log2_ceiling = int(math.ceil(math.log(float(int(width)), 2)))\r\n",
        "  next_power_of_two = 1 << log2_ceiling\r\n",
        "  count_mask = next_power_of_two - 1\r\n",
        "  mask_r0 = tf.constant(count_mask)\r\n",
        "  mask_r2 = tf.fill([height, k], mask_r0)\r\n",
        "  topk_r2_s32 = tf.bitcast(topk_r2, tf.int32)\r\n",
        "  topk_indices_r2 = tf.bitwise.bitwise_and(topk_r2_s32, mask_r2)\r\n",
        "  return topk_r2, topk_indices_r2\r\n",
        "\r\n",
        "\r\n",
        "def top_k_with_unique(inputs, k):\r\n",
        "  \"\"\"Finds the values and indices of the k largests entries.\r\n",
        "  Instead of doing sort like tf.nn.top_k, this function finds the max value\r\n",
        "  k times. The running time is proportional to k, which is be faster when k\r\n",
        "  is small. The current implementation supports only inputs of rank 2.\r\n",
        "  In addition, iota is used to replace the lower bits of each element, this\r\n",
        "  makes the selection more stable when there are equal elements. The\r\n",
        "  overhead is that output values are approximated.\r\n",
        "  Args:\r\n",
        "    inputs: A tensor with rank of 2. [batch_size, original_size].\r\n",
        "    k: An integer, number of top elements to select.\r\n",
        "  Returns:\r\n",
        "    top_values: A tensor, the k largest elements in sorted order.\r\n",
        "      [batch_size, k].\r\n",
        "    indices: A tensor, indices of the top_values. [batch_size, k].\r\n",
        "  \"\"\"\r\n",
        "  unique_inputs = _create_make_unique(tf.cast(inputs, tf.float32))\r\n",
        "  top_values, indices = _create_topk_unique(unique_inputs, k)\r\n",
        "  top_values = tf.cast(top_values, inputs.dtype)\r\n",
        "  return top_values, indices\r\n",
        "\r\n",
        "\r\n",
        "def compute_topk_scores_and_seq(sequences,\r\n",
        "                                scores,\r\n",
        "                                scores_to_gather,\r\n",
        "                                flags,\r\n",
        "                                beam_size,\r\n",
        "                                batch_size,\r\n",
        "                                prefix=\"default\",\r\n",
        "                                states_to_gather=None,\r\n",
        "                                use_tpu=True,\r\n",
        "                                use_top_k_with_unique=True):\r\n",
        "  \"\"\"Given sequences and scores, will gather the top k=beam size sequences.\r\n",
        "  This function is used to grow alive, and finished. It takes sequences,\r\n",
        "  scores, and flags, and returns the top k from sequences, scores_to_gather,\r\n",
        "  and flags based on the values in scores.\r\n",
        "  This method permits easy introspection using tfdbg.  It adds three named ops\r\n",
        "  that are prefixed by `prefix`:\r\n",
        "    - _topk_seq: the tensor for topk_seq returned by this method.\r\n",
        "    - _topk_flags: the tensor for topk_finished_flags returned by this method.\r\n",
        "    - _topk_scores: the tensor for tokp_gathered_scores returned by this method.\r\n",
        "  Args:\r\n",
        "    sequences: Tensor of sequences that we need to gather from.\r\n",
        "      [batch_size, beam_size, seq_length]\r\n",
        "    scores: Tensor of scores for each sequence in sequences.\r\n",
        "      [batch_size, beam_size]. We will use these to compute the topk.\r\n",
        "    scores_to_gather: Tensor of scores for each sequence in sequences.\r\n",
        "      [batch_size, beam_size]. We will return the gathered scores from here.\r\n",
        "      Scores to gather is different from scores because for grow_alive, we will\r\n",
        "      need to return log_probs, while for grow_finished, we will need to return\r\n",
        "      the length penalized scores.\r\n",
        "    flags: Tensor of bools for sequences that say whether a sequence has reached\r\n",
        "      EOS or not\r\n",
        "    beam_size: int\r\n",
        "    batch_size: int\r\n",
        "    prefix: string that will prefix unique names for the ops run.\r\n",
        "    states_to_gather: dict (possibly nested) of decoding states.\r\n",
        "    use_tpu: A bool, whether to compute topk scores and sequences on TPU.\r\n",
        "    use_top_k_with_unique: bool, whether to use a fast (but decreased precision)\r\n",
        "      top_k during TPU beam search.\r\n",
        "  Returns:\r\n",
        "    Tuple of\r\n",
        "    (topk_seq [batch_size, beam_size, decode_length],\r\n",
        "     topk_gathered_scores [batch_size, beam_size],\r\n",
        "     topk_finished_flags[batch_size, beam_size])\r\n",
        "  \"\"\"\r\n",
        "  if not use_tpu:\r\n",
        "    _, topk_indexes = tf.nn.top_k(scores, k=beam_size)\r\n",
        "    # The next three steps are to create coordinates for tf.gather_nd to pull\r\n",
        "    # out the topk sequences from sequences based on scores.\r\n",
        "    # batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which\r\n",
        "    # batch the beam item is in. This will create the i of the i,j coordinate\r\n",
        "    # needed for the gather\r\n",
        "    batch_pos = compute_batch_indices(batch_size, beam_size)\r\n",
        "\r\n",
        "    # top coordinates will give us the actual coordinates to do the gather.\r\n",
        "    # stacking will create a tensor of dimension batch * beam * 2, where the\r\n",
        "    # last dimension contains the i,j gathering coordinates.\r\n",
        "    top_coordinates = tf.stack([batch_pos, topk_indexes], axis=2)\r\n",
        "\r\n",
        "    # Gather up the highest scoring sequences.  For each operation added, give\r\n",
        "    # it a concrete name to simplify observing these operations with tfdbg.\r\n",
        "    # Clients can capture these tensors by watching these node names.\r\n",
        "    def gather(tensor, name):\r\n",
        "      return tf.gather_nd(tensor, top_coordinates, name=(prefix + name))\r\n",
        "    topk_seq = gather(sequences, \"_topk_seq\")\r\n",
        "    topk_flags = gather(flags, \"_topk_flags\")\r\n",
        "    topk_gathered_scores = gather(scores_to_gather, \"_topk_scores\")\r\n",
        "    if states_to_gather:\r\n",
        "      topk_gathered_states = nest.map_structure(\r\n",
        "          lambda state: gather(state, \"_topk_states\"), states_to_gather)\r\n",
        "    else:\r\n",
        "      topk_gathered_states = states_to_gather\r\n",
        "  else:\r\n",
        "    if use_top_k_with_unique:\r\n",
        "      _, topk_indexes = top_k_with_unique(scores, k=beam_size)\r\n",
        "    else:\r\n",
        "      _, topk_indexes = tf.nn.top_k(scores, k=beam_size)\r\n",
        "    # Gather up the highest scoring sequences.  For each operation added, give\r\n",
        "    # it a concrete name to simplify observing these operations with tfdbg.\r\n",
        "    # Clients can capture these tensors by watching these node names.\r\n",
        "    topk_seq = fast_tpu_gather(sequences, topk_indexes, prefix + \"_topk_seq\")\r\n",
        "    topk_flags = fast_tpu_gather(flags, topk_indexes, prefix + \"_topk_flags\")\r\n",
        "    topk_gathered_scores = fast_tpu_gather(scores_to_gather, topk_indexes,\r\n",
        "                                           prefix + \"_topk_scores\")\r\n",
        "    if states_to_gather:\r\n",
        "      topk_gathered_states = nest.map_structure(\r\n",
        "          # pylint: disable=g-long-lambda\r\n",
        "          lambda state: fast_tpu_gather(state, topk_indexes,\r\n",
        "                                        prefix + \"_topk_states\"),\r\n",
        "          states_to_gather)\r\n",
        "    else:\r\n",
        "      topk_gathered_states = states_to_gather\r\n",
        "  return topk_seq, topk_gathered_scores, topk_flags, topk_gathered_states\r\n",
        "\r\n",
        "\r\n",
        "def beam_search(symbols_to_logits_fn,\r\n",
        "                initial_ids,\r\n",
        "                beam_size,\r\n",
        "                decode_length,\r\n",
        "                vocab_size,\r\n",
        "                alpha,\r\n",
        "                states=None,\r\n",
        "                eos_id=EOS_ID,\r\n",
        "                stop_early=True,\r\n",
        "                use_tpu=False,\r\n",
        "                use_top_k_with_unique=True):\r\n",
        "  \"\"\"Beam search with length penalties.\r\n",
        "  Requires a function that can take the currently decoded symbols and return\r\n",
        "  the logits for the next symbol. The implementation is inspired by\r\n",
        "  https://arxiv.org/abs/1609.08144.\r\n",
        "  When running, the beam search steps can be visualized by using tfdbg to watch\r\n",
        "  the operations generating the output ids for each beam step.  These operations\r\n",
        "  have the pattern:\r\n",
        "    (alive|finished)_topk_(seq,scores)\r\n",
        "  Operations marked `alive` represent the new beam sequences that will be\r\n",
        "  processed in the next step.  Operations marked `finished` represent the\r\n",
        "  completed beam sequences, which may be padded with 0s if no beams finished.\r\n",
        "  Operations marked `seq` store the full beam sequence for the time step.\r\n",
        "  Operations marked `scores` store the sequence's final log scores.\r\n",
        "  The beam search steps will be processed sequentially in order, so when\r\n",
        "  capturing observed from these operations, tensors, clients can make\r\n",
        "  assumptions about which step is being recorded.\r\n",
        "  WARNING: Assumes 2nd dimension of tensors in `states` and not invariant, this\r\n",
        "  means that the shape of the 2nd dimension of these tensors will not be\r\n",
        "  available (i.e. set to None) inside symbols_to_logits_fn.\r\n",
        "  Args:\r\n",
        "    symbols_to_logits_fn: Interface to the model, to provide logits.\r\n",
        "        Shoud take [batch_size, decoded_ids] and return [batch_size, vocab_size]\r\n",
        "    initial_ids: Ids to start off the decoding, this will be the first thing\r\n",
        "        handed to symbols_to_logits_fn (after expanding to beam size)\r\n",
        "        [batch_size]\r\n",
        "    beam_size: Size of the beam.\r\n",
        "    decode_length: Number of steps to decode for.\r\n",
        "    vocab_size: Size of the vocab, must equal the size of the logits returned by\r\n",
        "        symbols_to_logits_fn\r\n",
        "    alpha: alpha for length penalty.\r\n",
        "    states: dict (possibly nested) of decoding states.\r\n",
        "    eos_id: ID for end of sentence.\r\n",
        "    stop_early: a boolean - stop once best sequence is provably determined.\r\n",
        "    use_tpu: A bool, whether to do beam search on TPU.\r\n",
        "    use_top_k_with_unique: bool, whether to use a fast (but decreased precision)\r\n",
        "      top_k during TPU beam search.\r\n",
        "  Returns:\r\n",
        "    Tuple of\r\n",
        "    (decoded beams [batch_size, beam_size, decode_length]\r\n",
        "     decoding probabilities [batch_size, beam_size])\r\n",
        "  \"\"\"\r\n",
        "  batch_size = common_layers.shape_list(initial_ids)[0]\r\n",
        "\r\n",
        "  # Assume initial_ids are prob 1.0\r\n",
        "  initial_log_probs = tf.constant([[0.] + [-INF] * (beam_size - 1)])\r\n",
        "  # Expand to beam_size (batch_size, beam_size)\r\n",
        "  alive_log_probs = tf.tile(initial_log_probs, [batch_size, 1])\r\n",
        "\r\n",
        "  # Expand each batch and state to beam_size\r\n",
        "  alive_seq = _expand_to_beam_size(initial_ids, beam_size)\r\n",
        "  alive_seq = tf.expand_dims(alive_seq, axis=2)  # (batch_size, beam_size, 1)\r\n",
        "  if use_tpu:\r\n",
        "    alive_seq = tf.tile(alive_seq, [1, 1, decode_length + 1])\r\n",
        "  if states:\r\n",
        "    states = nest.map_structure(\r\n",
        "        lambda state: _expand_to_beam_size(state, beam_size), states)\r\n",
        "  else:\r\n",
        "    states = {}\r\n",
        "\r\n",
        "  # Finished will keep track of all the sequences that have finished so far\r\n",
        "  # Finished log probs will be negative infinity in the beginning\r\n",
        "  # finished_flags will keep track of booleans\r\n",
        "  finished_seq = tf.zeros(common_layers.shape_list(alive_seq), tf.int32)\r\n",
        "  # Setting the scores of the initial to negative infinity.\r\n",
        "  finished_scores = tf.ones([batch_size, beam_size]) * -INF\r\n",
        "  finished_flags = tf.zeros([batch_size, beam_size], tf.bool)\r\n",
        "\r\n",
        "  def grow_finished(finished_seq, finished_scores, finished_flags, curr_seq,\r\n",
        "                    curr_scores, curr_finished):\r\n",
        "    \"\"\"Given sequences and scores, will gather the top k=beam size sequences.\r\n",
        "    Args:\r\n",
        "      finished_seq: Current finished sequences.\r\n",
        "        [batch_size, beam_size, current_decoded_length]\r\n",
        "      finished_scores: scores for each of these sequences.\r\n",
        "        [batch_size, beam_size]\r\n",
        "      finished_flags: finished bools for each of these sequences.\r\n",
        "        [batch_size, beam_size]\r\n",
        "      curr_seq: current topk sequence that has been grown by one position.\r\n",
        "        [batch_size, beam_size, current_decoded_length]\r\n",
        "      curr_scores: scores for each of these sequences. [batch_size, beam_size]\r\n",
        "      curr_finished: Finished flags for each of these sequences.\r\n",
        "        [batch_size, beam_size]\r\n",
        "    Returns:\r\n",
        "      Tuple of\r\n",
        "        (Topk sequences based on scores,\r\n",
        "         log probs of these sequences,\r\n",
        "         Finished flags of these sequences)\r\n",
        "    \"\"\"\r\n",
        "    if not use_tpu:\r\n",
        "      # First append a column of 0'ids to finished to make the same length with\r\n",
        "      # finished scores\r\n",
        "      finished_seq = tf.concat(\r\n",
        "          [finished_seq,\r\n",
        "           tf.zeros([batch_size, beam_size, 1], tf.int32)], axis=2)\r\n",
        "\r\n",
        "    # Set the scores of the unfinished seq in curr_seq to large negative\r\n",
        "    # values\r\n",
        "    curr_scores += (1. - tf.cast(curr_finished, dtype=tf.float32)) * -INF\r\n",
        "    # concatenating the sequences and scores along beam axis\r\n",
        "    curr_finished_seq = tf.concat([finished_seq, curr_seq], axis=1)\r\n",
        "    curr_finished_scores = tf.concat([finished_scores, curr_scores], axis=1)\r\n",
        "    curr_finished_flags = tf.concat([finished_flags, curr_finished], axis=1)\r\n",
        "    return compute_topk_scores_and_seq(\r\n",
        "        curr_finished_seq,\r\n",
        "        curr_finished_scores,\r\n",
        "        curr_finished_scores,\r\n",
        "        curr_finished_flags,\r\n",
        "        beam_size,\r\n",
        "        batch_size,\r\n",
        "        \"grow_finished\",\r\n",
        "        use_tpu=use_tpu,\r\n",
        "        use_top_k_with_unique=use_top_k_with_unique)\r\n",
        "\r\n",
        "  def grow_alive(curr_seq, curr_scores, curr_log_probs, curr_finished, states):\r\n",
        "    \"\"\"Given sequences and scores, will gather the top k=beam size sequences.\r\n",
        "    Args:\r\n",
        "      curr_seq: current topk sequence that has been grown by one position.\r\n",
        "        [batch_size, beam_size, i+1]\r\n",
        "      curr_scores: scores for each of these sequences. [batch_size, beam_size]\r\n",
        "      curr_log_probs: log probs for each of these sequences.\r\n",
        "        [batch_size, beam_size]\r\n",
        "      curr_finished: Finished flags for each of these sequences.\r\n",
        "        [batch_size, beam_size]\r\n",
        "      states: dict (possibly nested) of decoding states.\r\n",
        "    Returns:\r\n",
        "      Tuple of\r\n",
        "        (Topk sequences based on scores,\r\n",
        "         log probs of these sequences,\r\n",
        "         Finished flags of these sequences)\r\n",
        "    \"\"\"\r\n",
        "    # Set the scores of the finished seq in curr_seq to large negative\r\n",
        "    # values\r\n",
        "    curr_scores += tf.cast(curr_finished, dtype=tf.float32) * -INF\r\n",
        "    return compute_topk_scores_and_seq(curr_seq, curr_scores, curr_log_probs,\r\n",
        "                                       curr_finished, beam_size, batch_size,\r\n",
        "                                       \"grow_alive\", states, use_tpu=use_tpu)\r\n",
        "\r\n",
        "  def grow_topk(i, alive_seq, alive_log_probs, states):\r\n",
        "    r\"\"\"Inner beam search loop.\r\n",
        "    This function takes the current alive sequences, and grows them to topk\r\n",
        "    sequences where k = 2*beam. We use 2*beam because, we could have beam_size\r\n",
        "    number of sequences that might hit <EOS> and there will be no alive\r\n",
        "    sequences to continue. With 2*beam_size, this will not happen. This relies\r\n",
        "    on the assumption the vocab size is > beam size. If this is true, we'll\r\n",
        "    have at least beam_size non <EOS> extensions if we extract the next top\r\n",
        "    2*beam words.\r\n",
        "    Length penalty is given by = (5+len(decode)/6) ^ -\\alpha. Pls refer to\r\n",
        "    https://arxiv.org/abs/1609.08144.\r\n",
        "    Args:\r\n",
        "      i: loop index\r\n",
        "      alive_seq: Topk sequences decoded so far [batch_size, beam_size, i+1]\r\n",
        "      alive_log_probs: probabilities of these sequences. [batch_size, beam_size]\r\n",
        "      states: dict (possibly nested) of decoding states.\r\n",
        "    Returns:\r\n",
        "      Tuple of\r\n",
        "        (Topk sequences extended by the next word,\r\n",
        "         The log probs of these sequences,\r\n",
        "         The scores with length penalty of these sequences,\r\n",
        "         Flags indicating which of these sequences have finished decoding,\r\n",
        "         dict of transformed decoding states)\r\n",
        "    \"\"\"\r\n",
        "    # Get the logits for all the possible next symbols\r\n",
        "    if use_tpu and states:\r\n",
        "      flat_ids = tf.reshape(\r\n",
        "          tf.slice(alive_seq, [0, 0, i], [batch_size, beam_size, 1]),\r\n",
        "          [batch_size * beam_size, -1])\r\n",
        "    else:\r\n",
        "      flat_ids = tf.reshape(alive_seq, [batch_size * beam_size, -1])\r\n",
        "\r\n",
        "    # (batch_size * beam_size, decoded_length)\r\n",
        "    if states:\r\n",
        "      flat_states = nest.map_structure(_merge_beam_dim, states)\r\n",
        "      flat_logits, flat_states = symbols_to_logits_fn(flat_ids, i, flat_states)\r\n",
        "      states = nest.map_structure(\r\n",
        "          lambda t: _unmerge_beam_dim(t, batch_size, beam_size), flat_states)\r\n",
        "    elif use_tpu:\r\n",
        "      flat_logits = symbols_to_logits_fn(flat_ids, i)\r\n",
        "    else:\r\n",
        "      flat_logits = symbols_to_logits_fn(flat_ids)\r\n",
        "\r\n",
        "    logits = tf.reshape(flat_logits, [batch_size, beam_size, -1])\r\n",
        "\r\n",
        "    # Convert logits to normalized log probs\r\n",
        "    candidate_log_probs = common_layers.log_prob_from_logits(logits)\r\n",
        "\r\n",
        "    # Multiply the probabilities by the current probabilities of the beam.\r\n",
        "    # (batch_size, beam_size, vocab_size) + (batch_size, beam_size, 1)\r\n",
        "    log_probs = candidate_log_probs + tf.expand_dims(alive_log_probs, axis=2)\r\n",
        "\r\n",
        "    length_penalty = tf.pow(((5. + tf.cast(i + 1, dtype=tf.float32)) / 6.), alpha)\r\n",
        "\r\n",
        "    curr_scores = log_probs / length_penalty\r\n",
        "    # Flatten out (beam_size, vocab_size) probs in to a list of possibilities\r\n",
        "    flat_curr_scores = tf.reshape(curr_scores, [-1, beam_size * vocab_size])\r\n",
        "\r\n",
        "    if use_tpu and use_top_k_with_unique:\r\n",
        "      topk_scores, topk_ids = top_k_with_unique(\r\n",
        "          flat_curr_scores, k=beam_size * 2)\r\n",
        "    else:\r\n",
        "      topk_scores, topk_ids = tf.nn.top_k(flat_curr_scores, k=beam_size * 2)\r\n",
        "\r\n",
        "    # Recovering the log probs because we will need to send them back\r\n",
        "    topk_log_probs = topk_scores * length_penalty\r\n",
        "\r\n",
        "    # Work out what beam the top probs are in.\r\n",
        "    topk_beam_index = topk_ids // vocab_size\r\n",
        "    topk_ids %= vocab_size  # Unflatten the ids\r\n",
        "\r\n",
        "    if not use_tpu:\r\n",
        "      # The next three steps are to create coordinates for tf.gather_nd to pull\r\n",
        "      # out the correct sequences from id's that we need to grow.\r\n",
        "      # We will also use the coordinates to gather the booleans of the beam\r\n",
        "      # items that survived.\r\n",
        "      batch_pos = compute_batch_indices(batch_size, beam_size * 2)\r\n",
        "\r\n",
        "      # top beams will give us the actual coordinates to do the gather.\r\n",
        "      # stacking will create a tensor of dimension batch * beam * 2, where the\r\n",
        "      # last dimension contains the i,j gathering coordinates.\r\n",
        "      topk_coordinates = tf.stack([batch_pos, topk_beam_index], axis=2)\r\n",
        "\r\n",
        "      # Gather up the most probable 2*beams both for the ids and\r\n",
        "      # finished_in_alive bools\r\n",
        "      topk_seq = tf.gather_nd(alive_seq, topk_coordinates)\r\n",
        "      if states:\r\n",
        "        states = nest.map_structure(\r\n",
        "            lambda state: tf.gather_nd(state, topk_coordinates), states)\r\n",
        "\r\n",
        "      # Append the most probable alive\r\n",
        "      topk_seq = tf.concat([topk_seq, tf.expand_dims(topk_ids, axis=2)], axis=2)\r\n",
        "    else:\r\n",
        "      # Gather up the most probable 2*beams both for the ids and\r\n",
        "      # finished_in_alive bools\r\n",
        "      topk_seq = fast_tpu_gather(alive_seq, topk_beam_index)\r\n",
        "\r\n",
        "      if states:\r\n",
        "        states = nest.map_structure(\r\n",
        "            lambda state: fast_tpu_gather(state, topk_beam_index), states)\r\n",
        "\r\n",
        "      # Update the most probable alive\r\n",
        "      topk_seq = tf.transpose(a=topk_seq, perm=[2, 0, 1])\r\n",
        "      topk_seq = inplace_ops.alias_inplace_update(topk_seq, i + 1, topk_ids)\r\n",
        "      topk_seq = tf.transpose(a=topk_seq, perm=[1, 2, 0])\r\n",
        "\r\n",
        "    topk_finished = tf.equal(topk_ids, eos_id)\r\n",
        "\r\n",
        "    return topk_seq, topk_log_probs, topk_scores, topk_finished, states\r\n",
        "\r\n",
        "  def inner_loop(i, alive_seq, alive_log_probs, finished_seq, finished_scores,\r\n",
        "                 finished_flags, states):\r\n",
        "    \"\"\"Inner beam search loop.\r\n",
        "    There are three groups of tensors, alive, finished, and topk.\r\n",
        "    The alive group contains information about the current alive sequences\r\n",
        "    The topk group contains information about alive + topk current decoded words\r\n",
        "    the finished group contains information about finished sentences, that is,\r\n",
        "    the ones that have decoded to <EOS>. These are what we return.\r\n",
        "    The general beam search algorithm is as follows:\r\n",
        "    While we haven't terminated (pls look at termination condition)\r\n",
        "      1. Grow the current alive to get beam*2 topk sequences\r\n",
        "      2. Among the topk, keep the top beam_size ones that haven't reached EOS\r\n",
        "      into alive\r\n",
        "      3. Among the topk, keep the top beam_size ones have reached EOS into\r\n",
        "      finished\r\n",
        "    Repeat\r\n",
        "    To make things simple with using fixed size tensors, we will end\r\n",
        "    up inserting unfinished sequences into finished in the beginning. To stop\r\n",
        "    that we add -ve INF to the score of the unfinished sequence so that when a\r\n",
        "    true finished sequence does appear, it will have a higher score than all the\r\n",
        "    unfinished ones.\r\n",
        "    Args:\r\n",
        "      i: loop index\r\n",
        "      alive_seq: Topk sequences decoded so far [batch_size, beam_size, i+1]\r\n",
        "      alive_log_probs: probabilities of the beams. [batch_size, beam_size]\r\n",
        "      finished_seq: Current finished sequences.\r\n",
        "        [batch_size, beam_size, i+1]\r\n",
        "      finished_scores: scores for each of these sequences.\r\n",
        "        [batch_size, beam_size]\r\n",
        "      finished_flags: finished bools for each of these sequences.\r\n",
        "        [batch_size, beam_size]\r\n",
        "      states: dict (possibly nested) of decoding states.\r\n",
        "    Returns:\r\n",
        "      Tuple of\r\n",
        "        (Incremented loop index\r\n",
        "         New alive sequences,\r\n",
        "         Log probs of the alive sequences,\r\n",
        "         New finished sequences,\r\n",
        "         Scores of the new finished sequences,\r\n",
        "         Flags indicating which sequence in finished as reached EOS,\r\n",
        "         dict of final decoding states)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Each inner loop, we carry out three steps:\r\n",
        "    # 1. Get the current topk items.\r\n",
        "    # 2. Extract the ones that have finished and haven't finished\r\n",
        "    # 3. Recompute the contents of finished based on scores.\r\n",
        "    topk_seq, topk_log_probs, topk_scores, topk_finished, states = grow_topk(\r\n",
        "        i, alive_seq, alive_log_probs, states)\r\n",
        "    alive_seq, alive_log_probs, _, states = grow_alive(\r\n",
        "        topk_seq, topk_scores, topk_log_probs, topk_finished, states)\r\n",
        "    finished_seq, finished_scores, finished_flags, _ = grow_finished(\r\n",
        "        finished_seq, finished_scores, finished_flags, topk_seq, topk_scores,\r\n",
        "        topk_finished)\r\n",
        "\r\n",
        "    return (i + 1, alive_seq, alive_log_probs, finished_seq, finished_scores,\r\n",
        "            finished_flags, states)\r\n",
        "\r\n",
        "  def _is_not_finished(i, unused_alive_seq, alive_log_probs,\r\n",
        "                       unused_finished_seq, finished_scores,\r\n",
        "                       unused_finished_in_finished, unused_states):\r\n",
        "    \"\"\"Checking termination condition.\r\n",
        "    We terminate when we decoded up to decode_length or the lowest scoring item\r\n",
        "    in finished has a greater score that the highest prob item in alive divided\r\n",
        "    by the max length penalty\r\n",
        "    Args:\r\n",
        "      i: loop index\r\n",
        "      alive_log_probs: probabilities of the beams. [batch_size, beam_size]\r\n",
        "      finished_scores: scores for each of these sequences.\r\n",
        "        [batch_size, beam_size]\r\n",
        "    Returns:\r\n",
        "      Bool.\r\n",
        "    \"\"\"\r\n",
        "    max_length_penalty = tf.pow(((5. + tf.cast(decode_length, dtype=tf.float32)) / 6.), alpha)\r\n",
        "    # The best possible score of the most likely alive sequence.\r\n",
        "    lower_bound_alive_scores = alive_log_probs[:, 0] / max_length_penalty\r\n",
        "\r\n",
        "    if not stop_early:\r\n",
        "      # by considering the min score (in the top N beams) we ensure that\r\n",
        "      # the decoder will keep decoding until there is at least one beam\r\n",
        "      # (in the top N) that can be improved (w.r.t. the alive beams).\r\n",
        "      # any unfinished beam will have score -INF - thus the min\r\n",
        "      # will always be -INF if there is at least one unfinished beam -\r\n",
        "      # which means the bound_is_met condition cannot be true in this case.\r\n",
        "      lowest_score_of_finished_in_finished = tf.reduce_min(input_tensor=finished_scores)\r\n",
        "    else:\r\n",
        "      # by taking the max score we only care about the first beam;\r\n",
        "      # as soon as this first beam cannot be beaten from the alive beams\r\n",
        "      # the beam decoder can stop.\r\n",
        "      # similarly to the above, if the top beam is not completed, its\r\n",
        "      # finished_score is -INF, thus it will not activate the\r\n",
        "      # bound_is_met condition. (i.e., decoder will keep going on).\r\n",
        "      # note we need to find the max for every sequence eparately - so, we need\r\n",
        "      # to keep the batch dimension (see axis=1)\r\n",
        "      lowest_score_of_finished_in_finished = tf.reduce_max(input_tensor=finished_scores,\r\n",
        "                                                           axis=1)\r\n",
        "\r\n",
        "    bound_is_met = tf.reduce_all(\r\n",
        "        input_tensor=tf.greater(lowest_score_of_finished_in_finished,\r\n",
        "                   lower_bound_alive_scores))\r\n",
        "\r\n",
        "    return tf.logical_and(\r\n",
        "        tf.less(i, decode_length), tf.logical_not(bound_is_met))\r\n",
        "\r\n",
        "  inner_shape = tf.TensorShape([None, None, None])\r\n",
        "  if use_tpu:\r\n",
        "    inner_shape = tf.TensorShape([batch_size, beam_size, decode_length + 1])\r\n",
        "  if use_tpu:\r\n",
        "    state_struc = nest.map_structure(lambda state: state.get_shape(), states)\r\n",
        "  else:\r\n",
        "    state_struc = nest.map_structure(get_state_shape_invariants, states)\r\n",
        "  (_, alive_seq, alive_log_probs, finished_seq, finished_scores,\r\n",
        "   finished_flags, states) = tf.while_loop(\r\n",
        "       cond=_is_not_finished,\r\n",
        "       body=inner_loop, loop_vars=[\r\n",
        "           tf.constant(0), alive_seq, alive_log_probs, finished_seq,\r\n",
        "           finished_scores, finished_flags, states\r\n",
        "       ],\r\n",
        "       shape_invariants=[\r\n",
        "           tf.TensorShape([]),\r\n",
        "           inner_shape,\r\n",
        "           alive_log_probs.get_shape(),\r\n",
        "           inner_shape,\r\n",
        "           finished_scores.get_shape(),\r\n",
        "           finished_flags.get_shape(),\r\n",
        "           state_struc\r\n",
        "       ],\r\n",
        "       parallel_iterations=1,\r\n",
        "       back_prop=False)\r\n",
        "\r\n",
        "  alive_seq.set_shape((None, beam_size, None))\r\n",
        "  finished_seq.set_shape((None, beam_size, None))\r\n",
        "\r\n",
        "  # Accounting for corner case: It's possible that no sequence in alive for a\r\n",
        "  # particular batch item ever reached EOS. In that case, we should just copy\r\n",
        "  # the contents of alive for that batch item. tf.reduce_any(finished_flags, 1)\r\n",
        "  # if 0, means that no sequence for that batch index had reached EOS. We need\r\n",
        "  # to do the same for the scores as well.\r\n",
        "  finished_seq = tf.compat.v1.where(\r\n",
        "      tf.reduce_any(input_tensor=finished_flags, axis=1), finished_seq, alive_seq)\r\n",
        "  finished_scores = tf.compat.v1.where(\r\n",
        "      tf.reduce_any(input_tensor=finished_flags, axis=1), finished_scores, alive_log_probs)\r\n",
        "  return finished_seq, finished_scores, state"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensor2tensor'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-26-a6246a62f813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensor2tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommon_layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensor2tensor'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPgiilbmTBQW",
        "outputId": "6e543eff-a5c2-452a-ab39-9a36bec5ee2e"
      },
      "source": [
        "import datetime\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import logging\r\n",
        "\r\n",
        "def check_and_create_dir(path):\r\n",
        "    if not os.path.exists(path):\r\n",
        "      os.makedirs(path)\r\n",
        "      print(f'directory {path} created ')\r\n",
        "        \r\n",
        "# create folder in input_path if they don't exist\r\n",
        "if not config['use_tfds']:\r\n",
        "  assert (os.path.exists(file_path['train_csv_path'])), 'Training dataset not available'\r\n",
        "for key in file_path.keys():\r\n",
        "  if key in ['infer_ckpt_path' , 'G_drive_vocab_path', 'subword_vocab_path', 'log_path']:\r\n",
        "    pass\r\n",
        "  else:\r\n",
        "    if os.path.splitext(file_path[key])[1] == '':\r\n",
        "        check_and_create_dir(file_path[key])\r\n",
        "              \r\n",
        "# get TF logger\r\n",
        "log = logging.getLogger('tensorflow')\r\n",
        "log.setLevel(logging.DEBUG)\r\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\r\n",
        "fh = logging.FileHandler(file_path['log_path'])\r\n",
        "fh.setLevel(logging.DEBUG)\r\n",
        "fh.setFormatter(formatter)\r\n",
        "log.addHandler(fh)\r\n",
        "log.propagate = False\r\n",
        "\r\n",
        "if not tf.config.experimental.list_physical_devices('GPU'):\r\n",
        "    log.warning(\"GPU Not available so Running in CPU\")\r\n",
        "\r\n",
        "if config['run_tensorboard']:\r\n",
        "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "    train_log_dir = file_path['tensorboard_log'] + current_time + '/train'\r\n",
        "    validation_log_dir = file_path['tensorboard_log'] + current_time + '/validation'\r\n",
        "    train_summary_writer = tf.summary.create_file_writer(train_log_dir)\r\n",
        "    valid_summary_writer = tf.summary.create_file_writer(validation_log_dir)\r\n",
        "else:\r\n",
        "    train_summary_writer = None\r\n",
        "    valid_summary_writer = None\r\n",
        "        \r\n",
        "# create metrics dict\r\n",
        "monitor_metrics = dict()\r\n",
        "monitor_metrics['validation_loss'] = None\r\n",
        "monitor_metrics['BERT_f1'] = None\r\n",
        "monitor_metrics['ROUGE_f1'] = None\r\n",
        "monitor_metrics['validation_accuracy'] = None\r\n",
        "monitor_metrics['combined_metric'] = (\r\n",
        "                                      monitor_metrics['BERT_f1'], \r\n",
        "                                      monitor_metrics['ROUGE_f1'], \r\n",
        "                                      monitor_metrics['validation_accuracy']\r\n",
        "                                      )\r\n",
        "assert (config['monitor_metric'] in monitor_metrics.keys()), f'Available metrics to monitor are {monitor_metrics.keys()}'\r\n",
        "assert (tf.reduce_sum(h_parms['combined_metric_weights']) == 1), 'weights should sum to 1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoxEzL_LU6sd"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def get_angles(pos, i, d_model):\r\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\r\n",
        "  return pos * angle_rates\r\n",
        "\r\n",
        "def positional_encoding(position, d_model):\r\n",
        "  angle_rads = get_angles(\r\n",
        "                          np.arange(position)[:, np.newaxis],\r\n",
        "                          np.arange(d_model)[np.newaxis, :],\r\n",
        "                          d_model\r\n",
        "                          )\r\n",
        "  \r\n",
        "  # apply sin to even indices in the array; 2i\r\n",
        "  sines = np.sin(angle_rads[:, 0::2])\r\n",
        "  # apply cos to odd indices in the array; 2i+1\r\n",
        "  cosines = np.cos(angle_rads[:, 1::2])\r\n",
        "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\r\n",
        "  pos_encoding = pos_encoding[np.newaxis, ...]\r\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\r\n",
        "\r\n",
        "\r\n",
        "def create_padding_mask(seq):\r\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\r\n",
        "  \r\n",
        "  # add extra dimensions so that we can add the padding\r\n",
        "  # to the attention logits.\r\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\r\n",
        "\r\n",
        "def create_masks(inp, tar):\r\n",
        "  # Encoder padding mask\r\n",
        "  enc_padding_mask = create_padding_mask(inp)  #output 1 if padded 0 is present else 0\r\n",
        "  \r\n",
        "  # Used in the 2nd attention block in the decoder.\r\n",
        "  # This padding mask is used to mask the encoder outputs.\r\n",
        "  dec_padding_mask = create_padding_mask(inp)\r\n",
        "  # Used in the 1st attention block in the decoder.\r\n",
        "  # It is used to pad and mask future tokens in the input received by \r\n",
        "  # the decoder.allows decoder to attend to all positions in the decoder up to and including that position(refer architecture)\r\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\r\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\r\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\r\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask\r\n",
        "\r\n",
        "def create_look_ahead_mask(size):\r\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)  #(1 - lower_triangular_matrix)\r\n",
        "  return mask  # (seq_len, seq_len)\r\n",
        "\r\n",
        "def scaled_dot_product_attention(q, k, v, mask):\r\n",
        "  \"\"\"Calculate the attention weights.\r\n",
        "  q, k, v must have matching leading dimensions.\r\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\r\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \r\n",
        "  but it must be broadcastable for addition.\r\n",
        "  \r\n",
        "  Args:\r\n",
        "    q: query shape == (..., seq_len_q, depth)\r\n",
        "    k: key shape == (..., seq_len_k, depth)\r\n",
        "    v: value shape == (..., seq_len_v, depth_v)\r\n",
        "    mask: Float tensor with shape broadcastable \r\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\r\n",
        "    \r\n",
        "  Returns:\r\n",
        "    output, attention_weights\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\r\n",
        "  # scale matmul_qk\r\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\r\n",
        "  matmul_qk = tf.cast(matmul_qk, tf.float32)\r\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\r\n",
        "  # add the mask to the scaled tensor.\r\n",
        "  if mask is not None:\r\n",
        "    scaled_attention_logits += (mask * -1e9)  \r\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\r\n",
        "  # add up to 1.\r\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\r\n",
        "  v = tf.cast(v, tf.float32)\r\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\r\n",
        "  return output, attention_weights\r\n",
        "\r\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, d_model, num_heads):\r\n",
        "    super(MultiHeadAttention, self).__init__()\r\n",
        "    self.num_heads = num_heads\r\n",
        "    self.d_model = d_model\r\n",
        "    assert d_model % self.num_heads == 0, 'd_model should be a multiple of num_heads'\r\n",
        "    self.depth = d_model // self.num_heads\r\n",
        "    self.wq = tf.keras.layers.Dense(\r\n",
        "                                    d_model, \r\n",
        "                                    kernel_regularizer = tf.keras.regularizers.l2(h_parms['l2_norm']),\r\n",
        "                                    dtype='float32'\r\n",
        "                                    )\r\n",
        "    self.wk = tf.keras.layers.Dense(\r\n",
        "                                    d_model, \r\n",
        "                                    kernel_regularizer = tf.keras.regularizers.l2(h_parms['l2_norm']),\r\n",
        "                                    dtype='float32'\r\n",
        "                                    )\r\n",
        "    self.wv = tf.keras.layers.Dense(\r\n",
        "                                    d_model, \r\n",
        "                                    kernel_regularizer = tf.keras.regularizers.l2(h_parms['l2_norm']),\r\n",
        "                                    dtype='float32'\r\n",
        "                                    )\r\n",
        "    self.dense = tf.keras.layers.Dense(\r\n",
        "                                       d_model, \r\n",
        "                                       kernel_regularizer = tf.keras.regularizers.l2(h_parms['l2_norm']),\r\n",
        "                                       dtype='float32'\r\n",
        "                                       )\r\n",
        "        \r\n",
        "  def split_heads(self, x, batch_size):\r\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\r\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\r\n",
        "    \"\"\"\r\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\r\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\r\n",
        "    \r\n",
        "  def call(self, v, k, q, mask):\r\n",
        "    batch_size = tf.shape(q)[0]\r\n",
        "\r\n",
        "    # (batch_size, seq_len, d_model)\r\n",
        "    q = self.wq(q)  \r\n",
        "    # (batch_size, seq_len, d_model)\r\n",
        "    k = self.wk(k)  \r\n",
        "    # (batch_size, seq_len, d_model)\r\n",
        "    v = self.wv(v)  \r\n",
        "    # (batch_size, num_heads, seq_len_q, depth)\r\n",
        "    q = self.split_heads(q, batch_size)  \r\n",
        "    # (batch_size, num_heads, seq_len_k, depth)\r\n",
        "    k = self.split_heads(k, batch_size)  \r\n",
        "    # (batch_size, num_heads, seq_len_v, depth)\r\n",
        "    v = self.split_heads(v, batch_size)  \r\n",
        "    \r\n",
        "    # scaled_attention (batch_size, num_heads, seq_len_q, depth)\r\n",
        "    # attention_weights (batch_size, num_heads, seq_len_q, seq_len_k)\r\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\r\n",
        "        q, k, v, mask)\r\n",
        "    # (batch_size, seq_len_q, num_heads, depth)\r\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \r\n",
        "    # (batch_size, seq_len_q, d_model)\r\n",
        "    concat_attention = tf.reshape(scaled_attention, \r\n",
        "                                  (batch_size, -1, self.d_model)\r\n",
        "                                  )  \r\n",
        "    # (batch_size, seq_len_q, d_model)\r\n",
        "    output = self.dense(concat_attention)  \r\n",
        "        \r\n",
        "    return output, attention_weights\r\n",
        "\r\n",
        "# arg1 (batch_size, seq_len, dff)\r\n",
        "# arg2 (batch_size, seq_len, d_model)\r\n",
        "def point_wise_feed_forward_network(d_model, dff):\r\n",
        "  \r\n",
        "  return tf.keras.Sequential([\r\n",
        "      tf.keras.layers.Dense(dff, \r\n",
        "                            activation='relu', \r\n",
        "                            kernel_regularizer = tf.keras.regularizers.l2(h_parms['l2_norm']),\r\n",
        "                            dtype='float32'),\r\n",
        "      tf.keras.layers.Dense(d_model, \r\n",
        "                            kernel_regularizer = tf.keras.regularizers.l2(h_parms['l2_norm']),\r\n",
        "                            dtype='float32')\r\n",
        "  ])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class DecoderLayer(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, d_model, num_heads, dff, rate=h_parms['dropout_rate']):\r\n",
        "    super(DecoderLayer, self).__init__()\r\n",
        "\r\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\r\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\r\n",
        "\r\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\r\n",
        " \r\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6, dtype='float32')\r\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6, dtype='float32')\r\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6, dtype='float32')\r\n",
        "    \r\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate, dtype='float32')\r\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate, dtype='float32')\r\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate, dtype='float32')\r\n",
        "    \r\n",
        "    \r\n",
        "  def call(self, x, enc_output, training, \r\n",
        "           look_ahead_mask, padding_mask):\r\n",
        "    \r\n",
        "    \r\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  \r\n",
        "    attn1 = self.dropout1(attn1, training=training)\r\n",
        "    x = tf.cast(x, tf.float32)\r\n",
        "    out1 = self.layernorm1(attn1 + x)\r\n",
        "    attn2, attn_weights_block2 = self.mha2(\r\n",
        "        enc_output, enc_output, out1, padding_mask)  \r\n",
        "    attn2 = self.dropout2(attn2, training=training)\r\n",
        "    # (batch_size, target_seq_len, d_model)\r\n",
        "    out2 = self.layernorm2(attn2 + out1)  \r\n",
        "    # (batch_size, target_seq_len, d_model)\r\n",
        "    ffn_output = self.ffn(out2)  \r\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\r\n",
        "    # (batch_size, target_seq_len, d_model)\r\n",
        "    out3 = self.layernorm3(ffn_output + out2)  \r\n",
        "    return (out3, attn_weights_block1, attn_weights_block2)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Pointer_Generator(tf.keras.layers.Layer):\r\n",
        "  \r\n",
        "  def __init__(self):\r\n",
        "    super(Pointer_Generator, self).__init__()\r\n",
        "    \r\n",
        "    self.pointer_generator_layer = tf.keras.layers.Dense(\r\n",
        "                                                         1, \r\n",
        "                                                         kernel_regularizer = tf.keras.regularizers.l2(h_parms['l2_norm'])\r\n",
        "                                                        )\r\n",
        "    self.pointer_generator_vec   = tf.keras.layers.Activation('sigmoid', dtype='float32')\r\n",
        "    \r\n",
        "  def call(self, dec_output, final_output, \r\n",
        "          attention_weights, encoder_input, \r\n",
        "          inp_shape, tar_shape, training):\r\n",
        "\r\n",
        "    batch = tf.shape(encoder_input)[0]\r\n",
        "    # p_gen (batch_size, tar_seq_len, 1)\r\n",
        "    p_gen = self.pointer_generator_vec(self.pointer_generator_layer(dec_output))\r\n",
        "    # vocab_dist (batch_size, tar_seq_len, target_vocab_size)   \r\n",
        "    vocab_dist_ = tf.math.softmax(final_output, axis=-1)\r\n",
        "    vocab_dist = p_gen * vocab_dist_ \r\n",
        "    # attention_dist (batch_size, tar_seq_len, inp_seq_len)\r\n",
        "    # attention_weights is 4D so taking mean of the second dimension(i.e num_heads)\r\n",
        "    if h_parms['mean_attention_heads']:\r\n",
        "      attention_weights_ = tf.reduce_mean(attention_weights, axis=1)\r\n",
        "    else:\r\n",
        "      attention_weights_ = attention_weights[:, -1, :, :]\r\n",
        "    attention_dist = tf.math.softmax(attention_weights_, axis=-1)\r\n",
        "    # updates (batch_size, tar_seq_len, inp_seq_len)\r\n",
        "    updates = (1 - p_gen) * attention_dist\r\n",
        "    shape = tf.shape(final_output)\r\n",
        "    # represent the tokens indices in 3D using meshgrid and tile\r\n",
        "    # https://stackoverflow.com/questions/45162998/proper-usage-of-tf-scatter-nd-in-tensorflow-r1-2\r\n",
        "    i1, i2 = tf.meshgrid(tf.range(batch), tf.range(tar_shape), indexing=\"ij\")\r\n",
        "    i1 = tf.tile(i1[:, :, tf.newaxis], [1, 1, inp_shape])\r\n",
        "    i2 = tf.tile(i2[:, :, tf.newaxis], [1, 1, inp_shape])\r\n",
        "    # convert to int32 since they are compatible with scatter_nd\r\n",
        "    indices_ = tf.cast(encoder_input, dtype=tf.int32)\r\n",
        "    #tile on tar_seq_len so that the input vocab can be copied to output\r\n",
        "    indices_x = tf.tile(indices_[:, tf.newaxis,: ], [1, tar_shape, 1])\r\n",
        "    indices = tf.stack([i1, i2, indices_x], axis=-1)\r\n",
        "    # copy_probs (batch_size, tar_seq_len, target_vocab_size)\r\n",
        "    copy_probs = tf.scatter_nd(indices, updates, shape)   \r\n",
        "    # Added a small value to ensure numerical stability\r\n",
        "    combined_probs = vocab_dist + copy_probs\r\n",
        "    combined_logits = tf.math.log(combined_probs)\r\n",
        "    return combined_logits\r\n",
        "\r\n",
        "class Decoder(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \r\n",
        "               rate=h_parms['dropout_rate']):\r\n",
        "    super(Decoder, self).__init__()\r\n",
        "\r\n",
        "    self.d_model = d_model\r\n",
        "    self.num_layers = num_layers\r\n",
        "    #self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model, dtype='float32')\r\n",
        "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\r\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \r\n",
        "                       for _ in range(num_layers)]\r\n",
        "    self.dropout = tf.keras.layers.Dropout(rate, dtype='float32')\r\n",
        "    self.final_layer = tf.keras.layers.Dense(\r\n",
        "                                             target_vocab_size, \r\n",
        "                                             dtype='float32',\r\n",
        "                                             kernel_regularizer=tf.keras.regularizers.l2(h_parms['l2_norm']),                                                      \r\n",
        "                                             name='final_dense_layer'\r\n",
        "                                             )\r\n",
        "    if config['copy_gen']:\r\n",
        "      self.pointer_generator   = Pointer_Generator()\r\n",
        "    \r\n",
        "  def call(self, inp, x, enc_output, training, \r\n",
        "           look_ahead_mask, padding_mask):\r\n",
        "    seq_len = tf.shape(x)[1]\r\n",
        "    attention_weights = {}\r\n",
        "    # (batch_size, target_seq_len, d_model) \r\n",
        "    #x = self.embedding(x)  \r\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\r\n",
        "    x += self.pos_encoding[:, :seq_len, :]\r\n",
        "    x = self.dropout(x, training=training)\r\n",
        "    for i in range(self.num_layers):\r\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\r\n",
        "                                             look_ahead_mask, padding_mask)\r\n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\r\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\r\n",
        "    \r\n",
        "    if h_parms['mean_parameters_of_layers']:\r\n",
        "      # take mean of the block 2 attention heads of all the layers\r\n",
        "      block2_attention_weights = tf.reduce_mean(\r\n",
        "                                                [(attention_weights[key]) for key in attention_weights.keys() if 'block2' in key], \r\n",
        "                                                axis=0\r\n",
        "                                                )\r\n",
        "    else:\r\n",
        "      # take the attention weights of the final layer \r\n",
        "      block2_attention_weights = attention_weights[f'decoder_layer{self.num_layers}_block2']\r\n",
        "    \r\n",
        "    # (batch_size, tar_seq_len, target_vocab_size)\r\n",
        "    predictions = self.final_layer(tf.cast(x, tf.float32)) \r\n",
        "    if config['copy_gen']: \r\n",
        "      predictions = self.pointer_generator(\r\n",
        "                                        tf.cast(x, tf.float32),  #(batch_size, tar_seq_len, d_model)\r\n",
        "                                        predictions, \r\n",
        "                                        block2_attention_weights, \r\n",
        "                                        inp, \r\n",
        "                                        tf.shape(inp)[1], \r\n",
        "                                        seq_len, \r\n",
        "                                        training=training\r\n",
        "                                        )\r\n",
        "    # x (batch_size, target_seq_len, target_vocab_size)\r\n",
        "    return predictions, block2_attention_weights\r\n",
        "\r\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC_ry5zWVTw_"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from transformers import TFBertModel\r\n",
        "from tensorflow.keras.initializers import Constant\r\n",
        "\r\n",
        "# Special Tokens\r\n",
        "UNK_ID = 100\r\n",
        "CLS_ID = 101\r\n",
        "SEP_ID = 102\r\n",
        "MASK_ID = 103\r\n",
        "\r\n",
        "def tile_and_mask_diagonal(x, mask_with):\r\n",
        "    \"\"\"    \r\n",
        "    Masks each word in the summary draft one by one with the [MASK] token\r\n",
        "    At t-th time step the t-th word of input summary is\r\n",
        "    masked, and the decoder predicts the refined word given other\r\n",
        "    words of the summary.\r\n",
        "    \r\n",
        "    x :: (N, T)\r\n",
        "    returrn :: (N, T-1, T)\r\n",
        "    \r\n",
        "    We do not mask the first and last postition (corresponding to [CLS]\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    N, T = tf.shape(x)[0], tf.shape(x)[1]\r\n",
        "\r\n",
        "    first = tf.reshape(tf.tile(x[:, 0], [T-1]), [N, T-1, 1])\r\n",
        "    \r\n",
        "    x = x[:, 1:]\r\n",
        "    T = T - 1\r\n",
        "    \r\n",
        "    masked = tf.reshape(tf.tile(x, [1, T]), [N, T, T])\r\n",
        "    \r\n",
        "    diag = tf.ones([N, T], dtype=masked.dtype) * mask_with\r\n",
        "    masked = tf.linalg.set_diag(masked, diag)\r\n",
        "    \r\n",
        "    masked = tf.concat([first, masked], axis=2)\r\n",
        "    \r\n",
        "    masked = tf.reshape(masked, [N*T, T+1])\r\n",
        "    \r\n",
        "    return masked\r\n",
        "\r\n",
        "def _embedding_from_bert():\r\n",
        "\r\n",
        "  log.info(\"Extracting pretrained word embeddings weights from BERT\")  \r\n",
        "  vocab_of_BERT = TFBertModel.from_pretrained('bert-base-uncased', trainable=False, output_attentions=False,output_hidden_states=False)\r\n",
        "  embedding_matrix = vocab_of_BERT.get_weights()[0]\r\n",
        "  log.info(f\"Embedding matrix shape '{embedding_matrix.shape}'\")\r\n",
        "  return (embedding_matrix, vocab_of_BERT)\r\n",
        "\r\n",
        "class AbstractiveSummarization(tf.keras.Model):\r\n",
        "    \"\"\"\r\n",
        "    Pretraining-Based Natural Language Generation for Text Summarization \r\n",
        "    https://arxiv.org/pdf/1902.09243.pdf\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, output_seq_len, rate=0.1):\r\n",
        "        super(AbstractiveSummarization, self).__init__()\r\n",
        "        \r\n",
        "        self.output_seq_len = output_seq_len\r\n",
        "        self.vocab_size = vocab_size\r\n",
        "        embedding_matrix, self.bert_model = _embedding_from_bert()\r\n",
        "        self.embedding = tf.keras.layers.Embedding(\r\n",
        "                                                    vocab_size, d_model, trainable=False,\r\n",
        "                                                    embeddings_initializer=Constant(embedding_matrix)\r\n",
        "                                                   )\r\n",
        "        \r\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, vocab_size, rate)\r\n",
        "        self.d_model = d_model\r\n",
        "\r\n",
        "    def draft_summary(self,\r\n",
        "                      input_ids,\r\n",
        "                      enc_output,\r\n",
        "                      look_ahead_mask,\r\n",
        "                      padding_mask,\r\n",
        "                      target_ids,\r\n",
        "                      training):\r\n",
        "        # (batch_size, seq_len, d_bert)\r\n",
        "        embeddings = self.embedding(target_ids) \r\n",
        "        # (batch_size, seq_len, vocab_len), (_)            \r\n",
        "        draft_logits, draft_attention_dist = self.decoder(\r\n",
        "                                                          input_ids,\r\n",
        "                                                          embeddings, \r\n",
        "                                                          enc_output, \r\n",
        "                                                          training, \r\n",
        "                                                          look_ahead_mask, \r\n",
        "                                                          padding_mask\r\n",
        "                                                          )\r\n",
        "        # (batch_size, seq_len, vocab_len)\r\n",
        "        return draft_logits, draft_attention_dist\r\n",
        "\r\n",
        "    def refine_summary(self,\r\n",
        "                       input_ids, \r\n",
        "                       enc_output, \r\n",
        "                       target, \r\n",
        "                       padding_mask, \r\n",
        "                       training):\r\n",
        "\r\n",
        "        N = tf.shape(enc_output)[0]\r\n",
        "        T = self.output_seq_len\r\n",
        "        # (batch_size, seq_len) x3\r\n",
        "        dec_inp_ids, dec_inp_mask, dec_inp_segment_ids = target\r\n",
        "        # since we are using teacher forcing we do not need an autoregressice mechanism here\r\n",
        "        # (batch_size x (seq_len - 1), seq_len) \r\n",
        "        dec_inp_ids = tile_and_mask_diagonal(dec_inp_ids, mask_with=MASK_ID)\r\n",
        "        # (batch_size x (seq_len - 1), seq_len) \r\n",
        "        dec_inp_mask = tf.tile(dec_inp_mask, [T-1, 1])\r\n",
        "        # (batch_size x (seq_len - 1), seq_len) \r\n",
        "        dec_inp_segment_ids = tf.tile(dec_inp_segment_ids, [T-1, 1])\r\n",
        "        # (batch_size x (seq_len - 1), seq_len, d_bert) \r\n",
        "        enc_output = tf.tile(enc_output, [T-1, 1, 1])\r\n",
        "        # (batch_size x (seq_len - 1), 1, 1, seq_len) \r\n",
        "        padding_mask = tf.tile(padding_mask, [T-1, 1, 1, 1])\r\n",
        "        # (batch_size x (seq_len - 1), seq_len, d_bert)\r\n",
        "        context_vectors = self.bert_model(dec_inp_ids)[0]\r\n",
        "\r\n",
        "        # (batch_size x (seq_len - 1), seq_len, vocab_len), (_)\r\n",
        "        dec_outputs, refine_attention_dist = self.decoder(\r\n",
        "                                                           tf.tile(input_ids, [T-1, 1]),\r\n",
        "                                                           context_vectors,\r\n",
        "                                                           enc_output,\r\n",
        "                                                           training,\r\n",
        "                                                           look_ahead_mask=None,\r\n",
        "                                                           padding_mask=padding_mask\r\n",
        "                                                         )\r\n",
        "        # (batch_size x (seq_len - 1), seq_len - 1, vocab_len)\r\n",
        "        dec_outputs = dec_outputs[:, 1:, :]\r\n",
        "        # (batch_size x (seq_len - 1), (seq_len - 1))\r\n",
        "        diag = tf.linalg.set_diag(tf.zeros([T-1, T-1]), tf.ones([T-1]))\r\n",
        "        diag = tf.tile(diag, [N, 1])\r\n",
        "        \r\n",
        "        where = tf.not_equal(diag, 0)\r\n",
        "        indices = tf.where(where)\r\n",
        "        \r\n",
        "        # (batch_size x (seq_len - 1), vocab_len)\r\n",
        "        dec_outputs = tf.gather_nd(dec_outputs, indices)\r\n",
        "        \r\n",
        "        # (batch_size, seq_len - 1, vocab_len)\r\n",
        "        dec_outputs = tf.reshape(dec_outputs, [N, T-1, -1])\r\n",
        "        # (batch_size, seq_len, vocab_len)\r\n",
        "        refine_logits = tf.concat(\r\n",
        "                           [tf.tile(tf.expand_dims(tf.one_hot([CLS_ID], self.vocab_size), axis=0), [N, 1, 1]), dec_outputs],\r\n",
        "                           axis=1\r\n",
        "                           )\r\n",
        "\r\n",
        "\r\n",
        "        # (batch_size, seq_len, vocab_len)\r\n",
        "        return refine_logits, refine_attention_dist\r\n",
        "\r\n",
        "    def call(self, \r\n",
        "             input_ids, \r\n",
        "             input_mask, \r\n",
        "             input_segment_ids, \r\n",
        "             target_ids, \r\n",
        "             target_mask, \r\n",
        "             target_segment_ids, \r\n",
        "             training):\r\n",
        "\r\n",
        "           # (batch_size, 1, 1, seq_len), (batch_size, 1, 1, seq_len)\r\n",
        "        _, combined_mask, dec_padding_mask = create_masks(input_ids, target_ids[:, :-1])\r\n",
        "\r\n",
        "        # (batch_size, seq_len, d_bert)\r\n",
        "        enc_output = self.bert_model(input_ids)[0]\r\n",
        "\r\n",
        "        # (batch_size, seq_len, vocab_len), _\r\n",
        "        draft_logits, draft_attention_dist = self.draft_summary(\r\n",
        "                                                                input_ids,\r\n",
        "                                                                enc_output=enc_output,\r\n",
        "                                                                look_ahead_mask=combined_mask,\r\n",
        "                                                                padding_mask=dec_padding_mask,\r\n",
        "                                                                target_ids=target_ids[:, :-1],\r\n",
        "                                                                training=True\r\n",
        "                                                               )\r\n",
        "\r\n",
        "        # (batch_size, seq_len, vocab_len), _\r\n",
        "        refine_logits, refine_attention_dist = self.refine_summary(\r\n",
        "                                                                  input_ids,\r\n",
        "                                                                  enc_output=enc_output,\r\n",
        "                                                                  target=(target_ids[:, :-1], \r\n",
        "                                                                          target_mask[:, :-1], \r\n",
        "                                                                          target_segment_ids[:, :-1]),            \r\n",
        "                                                                  padding_mask=dec_padding_mask,\r\n",
        "                                                                  training=True\r\n",
        "                                                                  )\r\n",
        "              \r\n",
        "        return draft_logits, draft_attention_dist, refine_logits, refine_attention_dist"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180,
          "referenced_widgets": [
            "f81f7d06a57649e1ab9c69cca8b2d570",
            "d6dab8218c8142009af4f85d4d712875",
            "56f3046102894a0e9ba3c1f7b755e7c7",
            "6652120cd16449fca696c68e1af78928",
            "0bf11e04311a4b7aa17f74ea6d55a0b3",
            "d91b9f81bbde467996cee4b42572225f",
            "e8d5641033764bb2b8f1e14eab3d6c46",
            "0d845d9997db465b89430bb421b9e1ae",
            "fc0b15112f4540639020c1066fbecbe0",
            "c2d8a8c6cd024af9ae1eeeb926757b5b",
            "ca62ba232ffa4cfba54f2dbd51e6d8a8",
            "b58b1de516a64616966cef5a5af1946e",
            "f3257dbf8c694fa8b4a2c0ec0a549b7d",
            "d87222658f3f491b98ac0dbec598a1a4",
            "7bd2e9a368734f37937aad530be55983",
            "a030b3639c4247268ce2685f58dc3807",
            "4c3f6907e38c49f48c3c1ef1e4435e2b",
            "34460349d5d942e59aee78558f33c2a3",
            "e27845e12d4449c881a8ee3ea271f73b",
            "3d91540cadaf4bdca4de0ac70e30a79a",
            "165d5c36e041416f9822167f5b542551",
            "5fd80f6215c64b779c3c912f1f9f31fe",
            "ce5eb85a03df451da889afdd8f7a5680",
            "92bc5a96c06f4d53b1a81347943e9db7"
          ]
        },
        "id": "gyNQA9W5VxaG",
        "outputId": "af749dd4-632a-4642-c8e1-f7bd90d1bede"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import shutil\r\n",
        "import os\r\n",
        "from rouge import Rouge\r\n",
        "from bert_score import score as b_score\r\n",
        "log.info('Loading Pre-trained BERT model for BERT SCORE calculation')\r\n",
        "_, _, _ = b_score([\"I'm Batman\"], [\"I'm Spiderman\"], lang='en', model_type='bert-base-uncased')\r\n",
        "rouge_all = Rouge()\r\n",
        "\r\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n",
        "  def __init__(self, d_model, warmup_steps=4000):\r\n",
        "    super(CustomSchedule, self).__init__()\r\n",
        "    \r\n",
        "    self.d_model = d_model\r\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\r\n",
        "    self.warmup_steps = warmup_steps\r\n",
        "    \r\n",
        "  def __call__(self, step):\r\n",
        "    arg1 = tf.math.rsqrt(step)\r\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\r\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\r\n",
        "\r\n",
        "\r\n",
        "def label_smoothing(inputs, epsilon=h_parms['epsilon_ls']):\r\n",
        "    # number of channels\r\n",
        "    V = inputs.get_shape().as_list()[-1] \r\n",
        "    epsilon = tf.cast(epsilon, dtype=inputs.dtype)\r\n",
        "    V = tf.cast(V, dtype=inputs.dtype)\r\n",
        "    return ((1-epsilon) * inputs) + (epsilon / V)\r\n",
        "\r\n",
        "def convert_wordpiece_to_words(w_piece):\r\n",
        "  new=[]\r\n",
        "  for i in w_piece:\r\n",
        "    if '##' in i:\r\n",
        "      m = i.replace('##', '')\r\n",
        "    else:\r\n",
        "      if w_piece.index(i) == 0:\r\n",
        "        m = i\r\n",
        "      else:\r\n",
        "        m = ' '+i\r\n",
        "    new.append(m)\r\n",
        "  return (''.join(new))\r\n",
        "\r\n",
        "def loss_function(real, pred, mask):\r\n",
        "  # pred shape == real shape = (batch_size, tar_seq_len, target_vocab_size)\r\n",
        "  loss_ = loss_object(real, pred)\r\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\r\n",
        "  loss_ *= mask\r\n",
        "  return loss_\r\n",
        "\r\n",
        "def get_loss_and_accuracy():\r\n",
        "    loss = tf.keras.metrics.Mean()\r\n",
        "    accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\r\n",
        "    return(loss, accuracy)\r\n",
        "    \r\n",
        "def write_summary(tar_real, predictions, step, write=config['write_summary_op']):\r\n",
        "  r_avg_final = []\r\n",
        "  total_summary = []\r\n",
        "  for i, sub_tar_real in enumerate(tar_real):\r\n",
        "    predicted_id = tf.cast(tf.argmax(predictions[i], axis=-1), tf.int32)\r\n",
        "    #decoded_logits = argmax(predictions[i])\r\n",
        "    #predicted_id = tf.cast(decoded_logits, tf.int32)\r\n",
        "    sum_ref = tokenizer.convert_ids_to_tokens([i for i in sub_tar_real.numpy() if i not in [0, 101, 102]])\r\n",
        "    sum_hyp = tokenizer.convert_ids_to_tokens([i for i in predicted_id.numpy() if i not in [0, 101, 102]])\r\n",
        "    sum_ref = convert_wordpiece_to_words(sum_ref)\r\n",
        "    sum_hyp = convert_wordpiece_to_words(sum_hyp)\r\n",
        "    # don't consider empty values for ROUGE and BERT score calculation\r\n",
        "    if sum_hyp and sum_ref:\r\n",
        "      total_summary.append((sum_ref, sum_hyp))\r\n",
        "  ref_sents = [ref for ref, _ in total_summary]\r\n",
        "  hyp_sents = [hyp for _, hyp in total_summary]\r\n",
        "  # returns :- dict of dicts\r\n",
        "  if ref_sents and hyp_sents:\r\n",
        "      try:  \r\n",
        "        rouges = rouge_all.get_scores(ref_sents , hyp_sents)\r\n",
        "        avg_rouge_f1 = np.mean([np.mean([rouge_scores['rouge-1'][\"f\"], rouge_scores['rouge-2'][\"f\"], rouge_scores['rouge-l'][\"f\"]]) for rouge_scores in rouges])\r\n",
        "        _, _, bert_f1 = b_score(ref_sents, hyp_sents, lang='en', model_type='bert-base-uncased')\r\n",
        "        rouge_score =  avg_rouge_f1.astype('float64')\r\n",
        "        bert_f1_score =  np.mean(bert_f1.tolist(), dtype=np.float64)\r\n",
        "      except ValueError:\r\n",
        "        log.warning('Problem in calculating the ROUGE scores')\r\n",
        "        rouge_score = 0\r\n",
        "        bert_f1_score = 0\r\n",
        "  else:\r\n",
        "      log.warning('The sentences predicted by the model are empty so setting the scores to 0')\r\n",
        "      rouge_score = 0\r\n",
        "      bert_f1_score = 0\r\n",
        "  \r\n",
        "  if write and (step)%config['write_per_step'] == 0:\r\n",
        "    with tf.io.gfile.GFile(file_path['summary_write_path']+ str(step.numpy()), 'w') as f:\r\n",
        "      for ref, hyp in total_summary:\r\n",
        "        f.write(ref+'\\t'+hyp+'\\n')\r\n",
        "  return (rouge_score, bert_f1_score)\r\n",
        "  \r\n",
        "  \r\n",
        "def tf_write_summary(tar_real, predictions, step):\r\n",
        "  return tf.py_function(write_summary, [tar_real, predictions, step], Tout=[tf.float32, tf.float32])\r\n",
        "    \r\n",
        "\r\n",
        "def monitor_run(latest_ckpt, \r\n",
        "                ckpt_save_path, \r\n",
        "                val_loss, \r\n",
        "                val_acc,\r\n",
        "                bert_score, \r\n",
        "                rouge_score, \r\n",
        "                valid_summary_writer,\r\n",
        "                step,\r\n",
        "                to_monitor=config['monitor_metric']):\r\n",
        "  \r\n",
        "  ckpt_fold, ckpt_string = os.path.split(ckpt_save_path)\r\n",
        "  if config['run_tensorboard']:\r\n",
        "    with valid_summary_writer.as_default():\r\n",
        "      tf.summary.scalar('validation_total_loss', val_acc, step=step)\r\n",
        "      tf.summary.scalar('validation_total_accuracy', val_loss, step=step)\r\n",
        "      tf.summary.scalar('ROUGE_f1', rouge_score, step=step)\r\n",
        "      tf.summary.scalar('BERT_f1', bert_score, step=step)\r\n",
        "  monitor_metrics = dict()\r\n",
        "  monitor_metrics['validation_loss'] = val_loss\r\n",
        "  monitor_metrics['validation_accuracy'] = val_acc\r\n",
        "  monitor_metrics['BERT_f1'] = bert_score\r\n",
        "  monitor_metrics['ROUGE_f1'] = rouge_score\r\n",
        "  monitor_metrics['combined_metric'] = (\r\n",
        "                                        monitor_metrics['BERT_f1'], \r\n",
        "                                        monitor_metrics['ROUGE_f1'], \r\n",
        "                                        monitor_metrics['validation_accuracy']\r\n",
        "                                        )\r\n",
        "  # multiply with the weights                                    \r\n",
        "  monitor_metrics['combined_metric'] = round(tf.reduce_sum([(i*j) for i,j in zip(monitor_metrics['combined_metric'],  \r\n",
        "                                                                                 h_parms['combined_metric_weights'])]).numpy(), 2)\r\n",
        "  log.info(f\"combined_metric {monitor_metrics['combined_metric']:4f}\")\r\n",
        "  if to_monitor != 'validation_loss':\r\n",
        "    cond = (config['last_recorded_value'] < monitor_metrics[to_monitor])\r\n",
        "  else:\r\n",
        "    cond = (config['last_recorded_value'] > monitor_metrics[to_monitor])\r\n",
        "  if (latest_ckpt > config['monitor_only_after']) and cond:\r\n",
        "    # reset tolerance to zero if the monitor_metric decreases before the tolerance threshold\r\n",
        "    config['init_tolerance']=0\r\n",
        "    config['last_recorded_value'] =  monitor_metrics[to_monitor]\r\n",
        "    ckpt_files_tocopy = [files for files in os.listdir(os.path.split(ckpt_save_path)[0]) \\\r\n",
        "                         if ckpt_string in files]\r\n",
        "    log.info(f'{to_monitor} is {monitor_metrics[to_monitor]:4f} so checkpoint files {ckpt_string}           \\\r\n",
        "             will be copied to best checkpoint directory')\r\n",
        "    # copy the best checkpoints\r\n",
        "    shutil.copy2(os.path.join(ckpt_fold, 'checkpoint'), file_path.best_ckpt_path)\r\n",
        "    for files in ckpt_files_tocopy:\r\n",
        "        shutil.copy2(os.path.join(ckpt_fold, files), file_path.best_ckpt_path)\r\n",
        "  else:\r\n",
        "    config['init_tolerance'] +=1\r\n",
        "  # Warn and early stop\r\n",
        "  if config['init_tolerance'] > config['tolerance_threshold']:\r\n",
        "    log.warning('Tolerance exceeded')\r\n",
        "  if config['early_stop'] and config['init_tolerance'] > config['tolerance_threshold']:\r\n",
        "    log.info(f'Early stopping since the {to_monitor} reached the tolerance threshold')\r\n",
        "    return False\r\n",
        "  else:\r\n",
        "    return True\r\n",
        "\r\n",
        "lr = h_parms['learning_rate'] if h_parms['learning_rate'] else CustomSchedule(config['d_model'])    \r\n",
        "\r\n",
        "if h_parms['grad_clipnorm']:\r\n",
        "  optimizer = tf.keras.optimizers.Adam(\r\n",
        "                             learning_rate=lr, \r\n",
        "                             beta_1=0.9, \r\n",
        "                             beta_2=0.98, \r\n",
        "                             clipnorm=h_parms['grad_clipnorm'],\r\n",
        "                             epsilon=1e-9\r\n",
        "                             )\r\n",
        "else:\r\n",
        "  optimizer = tf.keras.optimizers.Adam(\r\n",
        "                             learning_rate=lr, \r\n",
        "                             beta_1=0.9, \r\n",
        "                             beta_2=0.98, \r\n",
        "                             epsilon=1e-9\r\n",
        "                             )\r\n",
        "\r\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy(\r\n",
        "                                                      from_logits=True, \r\n",
        "                                                      reduction='none'\r\n",
        "                                                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pToLIMUnYA2_"
      },
      "source": [
        "\r\n",
        "train_step_signature = [\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None, None), dtype=tf.float32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.bool),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.bool),\r\n",
        "                      tf.TensorSpec(shape=(None), dtype=tf.bool)\r\n",
        "                      ]\r\n",
        "\r\n",
        "val_step_signature = [\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None, None, None), dtype=tf.float32),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.bool),\r\n",
        "                      tf.TensorSpec(shape=(None, None), dtype=tf.bool),\r\n",
        "                      tf.TensorSpec(shape=(None), dtype=tf.int32),\r\n",
        "                      tf.TensorSpec(shape=(None), dtype=tf.bool)\r\n",
        "                     ]\r\n",
        "  \r\n",
        "model_metrics = 'Step {}\\n,\\\r\n",
        "                 Train Loss {:.4f}\\n,\\\r\n",
        "                 Train_Accuracy {:.4f}\\n,\\\r\n",
        "                 validation_loss {:.4f}\\n,\\\r\n",
        "                 validation_accuracy {:4f}\\n,\\\r\n",
        "                 ROUGE_f1 {:4f}\\n,\\\r\n",
        "                 BERT_f1 {:4f}\\n'\r\n",
        "evaluation_step  = 'Time taken for {} step : {} secs' \r\n",
        "checkpoint_details = 'Saving checkpoint at step {} on {}'\r\n",
        "batch_zero = 'Time taken to feed the input data to the model {} seconds'\r\n",
        "batch_run_details = 'Step {} Train_Loss {:.4f} Train_Accuracy {:.4f}'\r\n",
        "\r\n",
        "# run every batch\r\n",
        "def batch_run_check(batch, start, train_summary_writer, train_loss, train_accuracy, model):\r\n",
        "  if config['run_tensorboard']:\r\n",
        "    with train_summary_writer.as_default():\r\n",
        "      tf.summary.scalar('train_loss', train_loss, step=batch)\r\n",
        "      tf.summary.scalar('train_accuracy', train_accuracy, step=batch)\r\n",
        "  if batch==0:\r\n",
        "    log.info(model.summary())\r\n",
        "    log.info(batch_zero.format(time.time()-start))\r\n",
        "  log.info(\r\n",
        "           batch_run_details.format(\r\n",
        "                                   batch, \r\n",
        "                                   train_loss, \r\n",
        "                                   train_accuracy\r\n",
        "                                   )\r\n",
        "          )\r\n",
        "\r\n",
        "# run after each epoch\r\n",
        "def count_recs(batch, epoch, num_of_train_examples):\r\n",
        "  if epoch == 0:\r\n",
        "    try:\r\n",
        "      if batch > 0:\r\n",
        "        num_of_recs_post_filter_atmost = ((batch)*h_parms['batch_size'])/num_of_train_examples\r\n",
        "        log.info(f'Percentage of records used for training should be close to {num_of_recs_post_filter_atmost*100 :.2f}')\r\n",
        "    except NameError:\r\n",
        "      log.info('End of epoch')\r\n",
        "\r\n",
        "def calc_validation_loss(validation_dataset, \r\n",
        "                         step, \r\n",
        "                         val_step, \r\n",
        "                         valid_summary_writer, \r\n",
        "                         validation_loss, \r\n",
        "                         validation_accuracy):\r\n",
        "  total_val_acc_avg = tf.keras.metrics.Mean()\r\n",
        "  total_val_loss_avg = tf.keras.metrics.Mean()\r\n",
        "  for (batch, (input_ids, input_mask, input_segment_ids, target_ids_, target_mask, target_segment_ids)) in enumerate(validation_dataset.take(config.valid_samples_to_eval//h_parms.validation_batch_size)):\r\n",
        "    # calculate rouge for only the first batch\r\n",
        "    if batch == 0:\r\n",
        "      draft_mask = tf.math.logical_not(tf.math.equal(target_ids_[:, 1:], 0))\r\n",
        "      refine_mask = tf.math.logical_not(tf.math.equal(target_ids_[:, :-1], 0))\r\n",
        "      target_ids = label_smoothing(tf.one_hot(target_ids_, depth=config['input_vocab_size']))\r\n",
        "      rouge_score, bert_score = val_step(input_ids, \r\n",
        "                                         input_mask, \r\n",
        "                                         input_segment_ids, \r\n",
        "                                         target_ids_, \r\n",
        "                                         target_mask, \r\n",
        "                                         target_segment_ids, \r\n",
        "                                         target_ids, \r\n",
        "                                         draft_mask, \r\n",
        "                                         refine_mask, \r\n",
        "                                         step, \r\n",
        "                                         config['write_summary_op']\r\n",
        "                                         )\r\n",
        "    else:\r\n",
        "      _  =  val_step(input_ids, \r\n",
        "                     input_mask, \r\n",
        "                     input_segment_ids, \r\n",
        "                     target_ids_, \r\n",
        "                     target_mask, \r\n",
        "                     target_segment_ids, \r\n",
        "                     target_ids, \r\n",
        "                     draft_mask, \r\n",
        "                     refine_mask,\r\n",
        "                     step, \r\n",
        "                     False\r\n",
        "                     )\r\n",
        "    if config['run_tensorboard']:\r\n",
        "      with valid_summary_writer.as_default():\r\n",
        "        tf.summary.scalar('validation_loss', validation_loss.result(), step=batch)\r\n",
        "        tf.summary.scalar('validation_accuracy', validation_accuracy.result(), step=batch)\r\n",
        "  return (total_val_acc_avg(validation_accuracy.result()), \r\n",
        "          total_val_loss_avg(validation_loss.result()), \r\n",
        "          rouge_score, \r\n",
        "          bert_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bto_peN5Vetd"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.random.set_seed(100)\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "import tensorflow_addons as tfa\r\n",
        "\r\n",
        "UNK_ID = 100\r\n",
        "CLS_ID = 101\r\n",
        "SEP_ID = 102\r\n",
        "MASK_ID = 103\r\n",
        "\r\n",
        "def with_column(x, i, column):\r\n",
        "    \"\"\"\r\n",
        "    Given a tensor `x`, change its i-th column with `column`\r\n",
        "    x :: (N, T)\r\n",
        "    return :: (N, T)\r\n",
        "    \"\"\"\r\n",
        "    left = x[:, :i]\r\n",
        "    right = x[:, i+1:]\r\n",
        "        \r\n",
        "    return tf.concat([left, column, right], axis=1)\r\n",
        "\r\n",
        "def mask_timestamp(x, i, mask_with):\r\n",
        "    \"\"\"\r\n",
        "    Masks each word in the summary draft one by one with the [MASK] token\r\n",
        "    At t-th time step the t-th word of input summary is\r\n",
        "    masked, and the decoder predicts the refined word given other\r\n",
        "    words of the summary.\r\n",
        "    \r\n",
        "    x :: (N, T)\r\n",
        "    return :: (N, T)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    N, T = tf.shape(x)[0], tf.shape(x)[1]\r\n",
        "\r\n",
        "    left = x[:, :i]\r\n",
        "    right = x[:, i+1:]\r\n",
        "    \r\n",
        "    mask = tf.ones([N, 1], dtype=x.dtype) * mask_with\r\n",
        "    \r\n",
        "    masked = tf.concat([left, mask, right], axis=1)\r\n",
        "\r\n",
        "    return masked\r\n",
        "\r\n",
        "def create_padding_mask(seq):\r\n",
        "    \"\"\"\r\n",
        "    Mask all the pad tokens in the batch of sequence.\r\n",
        "    It ensures that the model does not treat padding as the input.\r\n",
        "    The mask indicates where pad value 0 is present:\r\n",
        "    it outputs a 1 at those locations, and a 0 otherwise.    \r\n",
        "    \"\"\"\r\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\r\n",
        "\r\n",
        "    # add extra dimensions so that we can add the padding\r\n",
        "    # to the attention logits.\r\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\r\n",
        "\r\n",
        "def sampling(logits):\r\n",
        "    sample = tf.random.categorical(logits, num_samples=1, dtype=tf.int32, seed=1)\r\n",
        "    return sample\r\n",
        "\r\n",
        "def top_k_sampling(logits, k=25):\r\n",
        "    'k must be greater than 0'\r\n",
        "    values, _ = tf.nn.top_k(logits, k=k)\r\n",
        "    min_value = tf.reduce_min(values)\r\n",
        "    logits = tf.where(\r\n",
        "        logits < min_value,\r\n",
        "        tf.ones_like(logits, dtype=logits.dtype) * -1e10,\r\n",
        "        logits)\r\n",
        "    logits = tf.reshape(logits, (h_parms.batch_size, -1))\r\n",
        "    sample = tf.random.categorical(logits, num_samples=1, dtype=tf.int32, seed=1)\r\n",
        "    return sample\r\n",
        "  \r\n",
        "def nucleus_sampling(logits, p=0.9):\r\n",
        "    sorted_logits = tf.sort(logits, direction='DESCENDING')\r\n",
        "    sorted_indices = tf.argsort(logits, direction='DESCENDING')\r\n",
        "    cumulative_probs = tf.cumsum(tf.nn.softmax(sorted_logits))\r\n",
        "    t_sorted_indices_to_remove = cumulative_probs > p\r\n",
        "    ''' Shift the indices to the right to keep also the first token above the threshold '''\r\n",
        "    indices = tf.range(1, tf.shape(logits)[0], 1)\r\n",
        "    sorted_indices_to_remove = tf.scatter_nd(\r\n",
        "                                             tf.expand_dims(indices, 1), \r\n",
        "                                             t_sorted_indices_to_remove[:-1], \r\n",
        "                                             logits.shape\r\n",
        "                                             )\r\n",
        "    logits = tf.where(\r\n",
        "        sorted_indices_to_remove,\r\n",
        "        tf.ones_like(logits, dtype=logits.dtype) * -1e10,\r\n",
        "        logits\r\n",
        "    )\r\n",
        "    logits = tf.reshape(logits, (h_parms.batch_size, -1))\r\n",
        "    sample = tf.random.categorical(logits, num_samples=1, dtype=tf.int32, seed=1)\r\n",
        "    return sample\r\n",
        "\r\n",
        "def topp_topk(logits, p, k):\r\n",
        "  sorted_logits = tf.sort(logits, direction='DESCENDING')\r\n",
        "  sorted_indices = tf.argsort(logits, direction='DESCENDING')\r\n",
        "  cumulative_probs = tf.cumsum(tf.nn.softmax(sorted_logits))\r\n",
        "  t_sorted_indices_to_remove = cumulative_probs > p\r\n",
        "  ''' Shift the indices to the right to keep also the first token above the threshold '''\r\n",
        "  indices = tf.range(1, tf.shape(logits)[0], 1)\r\n",
        "  sorted_indices_to_remove = tf.scatter_nd(\r\n",
        "                                           tf.expand_dims(indices, 1), \r\n",
        "                                           t_sorted_indices_to_remove[:-1], \r\n",
        "                                           logits.shape\r\n",
        "                                           )\r\n",
        "  logits = tf.where(\r\n",
        "      sorted_indices_to_remove,\r\n",
        "      tf.ones_like(logits, dtype=logits.dtype) * -1e10,\r\n",
        "      logits\r\n",
        "  )\r\n",
        "  values, _ = tf.nn.top_k(logits, k=k)\r\n",
        "  min_value = tf.reduce_min(values)\r\n",
        "  logits = tf.where(\r\n",
        "      logits < min_value,\r\n",
        "      tf.ones_like(logits, dtype=logits.dtype) * -1e10,\r\n",
        "      logits)\r\n",
        "  logits = tf.reshape(logits, (h_parms.batch_size, -1))\r\n",
        "  sample = tf.random.categorical(logits, num_samples=1, dtype=tf.int32, seed=1)\r\n",
        "  return sample\r\n",
        "# TODO stop decoding when the SEP_ID is predicted instead of looping till the end of summary len. \r\n",
        "def draft_summary_sampling(\r\n",
        "                           inp, \r\n",
        "                           enc_output, \r\n",
        "                           look_ahead_mask, \r\n",
        "                           padding_mask, \r\n",
        "                           sampling_type='greedy', \r\n",
        "                           temperature=0.9, \r\n",
        "                           p=0.9, \r\n",
        "                           k=25, \r\n",
        "                           training=False\r\n",
        "                           ):\r\n",
        "    \"\"\"\r\n",
        "    Inference call, builds a draft summary auto-regressively\r\n",
        "    \"\"\"\r\n",
        "    log.info(f\"Building: 'Draft {sampling_type} decoder'\")\r\n",
        "    N = tf.shape(enc_output)[0]\r\n",
        "    T = tf.shape(enc_output)[1]\r\n",
        "\r\n",
        "    # (batch_size, 1)\r\n",
        "    dec_input = tf.ones([N, 1], dtype=tf.int32) * CLS_ID\r\n",
        "    summary, dec_outputs, dec_logits, attention_dists = [], [], [], []\r\n",
        "    summary += [dec_input]\r\n",
        "    for i in (range(0, config['summ_length'])):\r\n",
        "        _, _, dec_padding_mask = create_masks(inp, dec_input)\r\n",
        "        # (batch_size, i+1, d_bert)\r\n",
        "        embeddings = model.embedding(dec_input)    \r\n",
        "\r\n",
        "        # (batch_size, i+1, vocab), (_)            \r\n",
        "        dec_output, dec_logits_i, attention_dist = model.decoder(\r\n",
        "                                                                embeddings, \r\n",
        "                                                                enc_output, \r\n",
        "                                                                training, \r\n",
        "                                                                look_ahead_mask, \r\n",
        "                                                                padding_mask\r\n",
        "                                                               )\r\n",
        "\r\n",
        "        if config['copy_gen']:\r\n",
        "          dec_output = model.decoder.pointer_generator(\r\n",
        "                                                        dec_logits_i, \r\n",
        "                                                        dec_output,\r\n",
        "                                                        attention_dist,\r\n",
        "                                                        inp,\r\n",
        "                                                        tf.shape(inp)[1], \r\n",
        "                                                        tf.shape(dec_output)[1], \r\n",
        "                                                        training=False,\r\n",
        "                                                       )\r\n",
        "        \r\n",
        "\r\n",
        "        # (batch_size, 1, vocab)\r\n",
        "        dec_output_i = dec_output[:, -1: ,:]\r\n",
        "        if sampling_type == 'nucleus':\r\n",
        "          preds = tf.cast(nucleus_sampling(((dec_output_i)/ temperature), p=p), tf.int32)\r\n",
        "        elif sampling_type == 'topk':\r\n",
        "          preds = tf.cast(top_k_sampling(((dec_output_i)/ temperature), k=k), tf.int32)\r\n",
        "        elif sampling_type == 'random_sampling':\r\n",
        "          preds = tf.cast(sampling((dec_output_i)/ temperature), tf.int32)\r\n",
        "        elif sampling_type == 'topktopp':\r\n",
        "              preds = tf.cast(topp_topk(((dec_output_i)/ temperature), p=p,k=k), tf.int32)\r\n",
        "        else:\r\n",
        "          preds = tf.cast(tf.argmax(dec_output_i, axis=-1), tf.int32)\r\n",
        "        dec_outputs += [dec_output_i]\r\n",
        "        dec_logits_i = dec_logits_i[:, -1:, :]\r\n",
        "        dec_logits += [dec_logits_i]\r\n",
        "        summary += [preds]\r\n",
        "        dec_input = with_column(dec_input, i+1, preds)\r\n",
        "    summary = tf.concat(summary, axis=1)  \r\n",
        "    # (batch_size, seq_len, vocab_len), (batch_size, seq_len), (_)\r\n",
        "    return summary, attention_dist\r\n",
        "\r\n",
        "def draft_summary_beam_search(input_ids, enc_output, dec_padding_mask, beam_size):\r\n",
        "\r\n",
        "    log.info(f\"Building: 'Draft beam search decoder'\")\r\n",
        "    input_ids = tfa.seq2seq.tile_batch(input_ids, multiplier=beam_size)\r\n",
        "    enc_output = tfa.seq2seq.tile_batch(enc_output, multiplier=beam_size)\r\n",
        "    dec_padding_mask = tfa.seq2seq.tile_batch(dec_padding_mask, multiplier=beam_size)\r\n",
        "    def beam_search_decoder(output):\r\n",
        "      # (batch_size, seq_len, d_bert)    \r\n",
        "      embeddings = model.embedding(output)\r\n",
        "      predictions, dec_op, attention_weights = model.decoder(\r\n",
        "                                                            embeddings, \r\n",
        "                                                            enc_output, \r\n",
        "                                                            False, \r\n",
        "                                                            None, \r\n",
        "                                                            dec_padding_mask\r\n",
        "                                                            )\r\n",
        "      if config['copy_gen']:\r\n",
        "        predictions = model.decoder.pointer_generator(\r\n",
        "                                                      dec_op[:, -1:, :], \r\n",
        "                                                      predictions[:, -1:, :],\r\n",
        "                                                      attention_weights[:, :, -1:, :],\r\n",
        "                                                      input_ids,\r\n",
        "                                                      tf.shape(input_ids)[1], \r\n",
        "                                                      tf.shape(predictions[:, -1:, :])[1], \r\n",
        "                                                      training=False,\r\n",
        "                                                     )\r\n",
        "      # (batch_size, 1, target_vocab_size)\r\n",
        "      return (predictions[:,-1:,:])\r\n",
        "    return beam_search(\r\n",
        "                        beam_search_decoder, \r\n",
        "                        [CLS_ID] * h_parms.batch_size, \r\n",
        "                        beam_size, \r\n",
        "                        config['summ_length'], \r\n",
        "                        config['input_vocab_size'], \r\n",
        "                        h_parms['length_penalty'], \r\n",
        "                        stop_early=False, \r\n",
        "                        eos_id=[[SEP_ID]]\r\n",
        "                        )\r\n",
        "            \r\n",
        "\r\n",
        "def refined_summary_sampling(inp, \r\n",
        "                           enc_output, \r\n",
        "                           draft_summary, \r\n",
        "                           padding_mask, \r\n",
        "                           sampling_type='greedy', \r\n",
        "                           temperature=0.9, \r\n",
        "                           p=0.9, \r\n",
        "                           k=25,\r\n",
        "                           training=False):\r\n",
        "        \"\"\"\r\n",
        "        Inference call, builds a refined summary\r\n",
        "        \r\n",
        "        It first masks each word in the summary draft one by one,\r\n",
        "        then feeds the draft to BERT to generate context vectors.\r\n",
        "        \"\"\"\r\n",
        "        \r\n",
        "        log.info(f\"Building: 'Refined {sampling_type} decoder'\")\r\n",
        "        N = tf.shape(enc_output)[0]\r\n",
        "        refined_summary = draft_summary\r\n",
        "        batch = tf.shape(draft_summary)[0]\r\n",
        "        dec_outputs = []\r\n",
        "        dec_logits = []\r\n",
        "        attention_dists = []\r\n",
        "        for i in (range(1, config['summ_length'])):\r\n",
        "            \r\n",
        "            # (batch_size, seq_len)\r\n",
        "            refined_summary_ = mask_timestamp(refined_summary, i, MASK_ID)\r\n",
        "            \r\n",
        "            # (batch_size, seq_len, d_bert)\r\n",
        "            context_vectors = model.bert_model(refined_summary_)[0]\r\n",
        "            \r\n",
        "            # (batch_size, seq_len, d_bert), (_)\r\n",
        "            dec_output, dec_logits_i, attention_dist = model.decoder(\r\n",
        "                                                                    context_vectors,\r\n",
        "                                                                    enc_output,\r\n",
        "                                                                    training=training,\r\n",
        "                                                                    look_ahead_mask=None,\r\n",
        "                                                                    padding_mask=padding_mask\r\n",
        "                                                                  )\r\n",
        "            \r\n",
        "            # (batch_size, 1, vocab_len)\r\n",
        "            dec_output_i = dec_output[:, i:i+1 ,:]\r\n",
        "            if sampling_type == 'nucleus':\r\n",
        "              preds = tf.cast(nucleus_sampling((dec_output_i/ temperature), p=p), tf.int32)\r\n",
        "            elif sampling_type == 'topk':\r\n",
        "              preds = tf.cast(top_k_sampling(((dec_output_i)/ temperature), k=k), tf.int32)\r\n",
        "            elif sampling_type == 'topktopp':\r\n",
        "              preds = tf.cast(topp_topk(((dec_output_i)/ temperature), p=p,k=k), tf.int32)\r\n",
        "            elif sampling_type == 'random_sampling':\r\n",
        "              preds = tf.cast(sampling((dec_output_i)/ temperature), tf.int32)\r\n",
        "            else:\r\n",
        "              preds = tf.cast(tf.argmax(dec_output_i, axis=-1), tf.int32)\r\n",
        "            refined_summary = with_column(refined_summary, i, preds)\r\n",
        "        # (batch_size, seq_len, vocab_len), (_)        \r\n",
        "        return refined_summary, attention_dist\r\n",
        "\r\n",
        "def predict_using_sampling(\r\n",
        "                           inp, \r\n",
        "                           draft_decoder_sampling_type='topk',\r\n",
        "                           refine_decoder_sampling_type='topk', \r\n",
        "                           temperature=0.9, \r\n",
        "                           p=0.9, \r\n",
        "                           k=25):\r\n",
        "  \r\n",
        "  dec_padding_mask = create_padding_mask(inp)\r\n",
        "  \r\n",
        "  # (batch_size, seq_len, d_bert)\r\n",
        "  enc_output = model.bert_model(inp)[0]\r\n",
        "  # (batch_size, seq_len, vocab_len), (_)\r\n",
        "  preds_draft_summary, draft_attention_dist = draft_summary_sampling( \r\n",
        "                                                                      inp,\r\n",
        "                                                                      enc_output=enc_output,\r\n",
        "                                                                      look_ahead_mask=None,\r\n",
        "                                                                      padding_mask=dec_padding_mask,\r\n",
        "                                                                      sampling_type=draft_decoder_sampling_type,\r\n",
        "                                                                      temperature=temperature,\r\n",
        "                                                                      p=p, \r\n",
        "                                                                      k=k,\r\n",
        "                                                                    )\r\n",
        "  # (batch_size, seq_len, vocab_len), ()\r\n",
        "  preds_refined_summary, refined_attention_dist = refined_summary_sampling(\r\n",
        "                                                                            inp,\r\n",
        "                                                                            enc_output=enc_output,\r\n",
        "                                                                            padding_mask=dec_padding_mask,\r\n",
        "                                                                            draft_summary=preds_draft_summary,\r\n",
        "                                                                            sampling_type=refine_decoder_sampling_type, \r\n",
        "                                                                            temperature=temperature, \r\n",
        "                                                                            p=p, \r\n",
        "                                                                            k=k\r\n",
        "                                                                            )\r\n",
        "\r\n",
        "\r\n",
        "  return preds_draft_summary, draft_attention_dist, preds_refined_summary, refined_attention_dist\r\n",
        "\r\n",
        "def predict_using_beam_search(\r\n",
        "                              inp, \r\n",
        "                              beam_size=3, \r\n",
        "                              refine_decoder_sampling_type='nucleus', \r\n",
        "                              temperature=0.9, \r\n",
        "                              p=0.9, \r\n",
        "                              k=25):\r\n",
        "  \r\n",
        "  dec_padding_mask = create_padding_mask(inp)\r\n",
        "  # (batch_size, seq_len, d_bert)\r\n",
        "  enc_output = model.bert_model(inp)[0]\r\n",
        "  \r\n",
        "  #[batch_size*beam_size, input_Seq_len, d_bert]\r\n",
        "  translated_output_temp = draft_summary_beam_search(inp, enc_output, dec_padding_mask, beam_size)\r\n",
        "  # Take the sequence with high score (the last one)\r\n",
        "  preds_draft_summary = translated_output_temp[0][:,0,:] \r\n",
        "  \r\n",
        "  preds_refined_summary, refined_attention_dist = refined_summary_sampling(\r\n",
        "                                                                        inp,\r\n",
        "                                                                        enc_output=enc_output,\r\n",
        "                                                                        padding_mask=dec_padding_mask,\r\n",
        "                                                                        draft_summary=preds_draft_summary, \r\n",
        "                                                                        sampling_type=refine_decoder_sampling_type, \r\n",
        "                                                                        temperature=temperature, \r\n",
        "                                                                        p=p, \r\n",
        "                                                                        k=k\r\n",
        "                                                                        )\r\n",
        "  return preds_draft_summary, preds_refined_summary, refined_attention_dist"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iw_yamwYIR7"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "from functools import partial\r\n",
        "\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "# Special Tokens\r\n",
        "UNK_ID = 100\r\n",
        "CLS_ID = 101\r\n",
        "SEP_ID = 102\r\n",
        "MASK_ID = 103\r\n",
        "\r\n",
        "def create_dataframe(path, num_examples):\r\n",
        "    df = pd.read_csv(path)\r\n",
        "    df.columns = [i.capitalize() for i in df.columns if i.lower() in ['document', 'summary']]\r\n",
        "    assert len(df.columns) == 2, 'column names should be document and summary'\r\n",
        "    df = df[:num_examples]\r\n",
        "    assert not df.isnull().any().any(), 'dataset contains  nans'\r\n",
        "    return (df[\"Document\"].values, df[\"Summary\"].values)\r\n",
        "    \r\n",
        "def pad(l, n, pad=0):\r\n",
        "    \"\"\"\r\n",
        "    Pad the list 'l' to have size 'n' using 'padding_element'\r\n",
        "    \"\"\"\r\n",
        "    pad_with = (0, max(0, n - len(l)))\r\n",
        "    return np.pad(l, pad_with, mode='constant', constant_values=pad)\r\n",
        "\r\n",
        "\r\n",
        "def encode(sent_1, sent_2, tokenizer, input_seq_len, output_seq_len):\r\n",
        "    \"\"\"\r\n",
        "    Encode the text to the BERT expected format\r\n",
        "    \r\n",
        "    'input_seq_len' is used to truncate the the article length\r\n",
        "    'output_seq_len' is used to truncate the the summary length\r\n",
        "    BERT has the following special tokens:    \r\n",
        "    \r\n",
        "    [CLS] : The first token of every sequence. A classification token\r\n",
        "    which is normally used in conjunction with a softmax layer for classification\r\n",
        "    tasks. For anything else, it can be safely ignored.\r\n",
        "    [SEP] : A sequence delimiter token which was used at pre-training for\r\n",
        "    sequence-pair tasks (i.e. Next sentence prediction). Must be used when\r\n",
        "    sequence pair tasks are required. When a single sequence is used it is just appended at the end.\r\n",
        "    [MASK] : Token used for masked words. Only used for pre-training.\r\n",
        "    \r\n",
        "    Additionally BERT requires additional inputs to work correctly:\r\n",
        "        - Mask IDs\r\n",
        "        - Segment IDs\r\n",
        "    \r\n",
        "    The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\r\n",
        "    Sentence Embeddings is just a numeric class to distinguish between pairs of sentences.\r\n",
        "    \"\"\"\r\n",
        "    input_ids_1 = tokenizer.encode(sent_1.numpy().decode('utf-8'))\r\n",
        "    input_ids_2 = tokenizer.encode(sent_2.numpy().decode('utf-8'))\r\n",
        "    \r\n",
        "    # Account for [CLS] and [SEP] with \"- 2\"\r\n",
        "    if len(input_ids_1) > input_seq_len - 2:\r\n",
        "        input_ids_1 = input_ids_1[0:(input_seq_len - 2)]\r\n",
        "    if len(input_ids_2) > (output_seq_len + 1) - 2:\r\n",
        "        input_ids_2 = input_ids_2[0:((output_seq_len + 1) - 2)]\r\n",
        "        \r\n",
        "    input_mask_1 = [1] * len(input_ids_1)\r\n",
        "    input_mask_2 = [1] * len(input_ids_2)\r\n",
        "\r\n",
        "    input_ids_1 = pad(input_ids_1, input_seq_len, 0)\r\n",
        "    input_ids_2 = pad(input_ids_2, output_seq_len + 1, 0)\r\n",
        "    input_mask_1 = pad(input_mask_1, input_seq_len, 0)\r\n",
        "    input_mask_2 = pad(input_mask_2, output_seq_len + 1, 0)\r\n",
        "    \r\n",
        "    input_type_ids_1 = [0] * len(input_ids_1)\r\n",
        "    input_type_ids_2 = [0] * len(input_ids_2)\r\n",
        "    \r\n",
        "    return input_ids_1, input_mask_1, input_type_ids_1, input_ids_2, input_mask_2, input_type_ids_2\r\n",
        "\r\n",
        "\r\n",
        "def tf_encode(tokenizer, input_seq_len, output_seq_len):\r\n",
        "    \"\"\"\r\n",
        "    Operations inside `.map()` run in graph mode and receive a graph\r\n",
        "    tensor that do not have a `numpy` attribute.\r\n",
        "    The tokenizer expects a string or Unicode symbol to encode it into integers.\r\n",
        "    Hence, you need to run the encoding inside a `tf.py_function`,\r\n",
        "    which receives an eager tensor having a numpy attribute that contains the string value.\r\n",
        "    \"\"\"    \r\n",
        "    def f(s1, s2):\r\n",
        "        encode_ = partial(encode, tokenizer=tokenizer, input_seq_len=input_seq_len, output_seq_len=output_seq_len)\r\n",
        "        return tf.py_function(encode_, [s1, s2], [tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32])\r\n",
        "    \r\n",
        "    return f\r\n",
        "\r\n",
        "# Set threshold for document and  summary length\r\n",
        "def filter_max_length(x, x1, x2, y, y1, y2):\r\n",
        "    return tf.logical_and(\r\n",
        "                          tf.size(x[0]) <= config['doc_length'],\r\n",
        "                          tf.size(y[0]) <= config['doc_length']\r\n",
        "                         )\r\n",
        "\r\n",
        "def filter_combined_length(x, x1, x2, y, y1, y2):\r\n",
        "    return tf.math.less_equal(\r\n",
        "                              (tf.math.count_nonzero(x) + tf.math.count_nonzero(y)), \r\n",
        "                              config['max_tokens_per_line']\r\n",
        "                             )\r\n",
        "                        \r\n",
        "# this function should be added after padded batch step\r\n",
        "def filter_batch_token_size(x, x1, x2, y, y1, y2):\r\n",
        "    return tf.math.less_equal(\r\n",
        "                              (tf.size(x[0]) + tf.size(y[0])), \r\n",
        "                              config['max_tokens_per_line']*h_parms['batch_size']\r\n",
        "                             )\r\n",
        "    \r\n",
        "def map_batch_shuffle(dataset, buffer_size, split, \r\n",
        "                      shuffle=True, batch_size=h_parms['batch_size'],\r\n",
        "                      filter_off=False):\r\n",
        "    tf_dataset = dataset.map(\r\n",
        "                            tf_encode(\r\n",
        "                                tokenizer, \r\n",
        "                                config['doc_length'], \r\n",
        "                                config['summ_length']\r\n",
        "                                ), num_parallel_calls=tf.data.experimental.AUTOTUNE\r\n",
        "                            )\r\n",
        "    if not filter_off:\r\n",
        "        tf_dataset = tf_dataset.filter(filter_combined_length)\r\n",
        "    tf_dataset = tf_dataset.cache()\r\n",
        "    if split == 'train' and shuffle and (not config['use_tfds']):\r\n",
        "       tf_dataset = tf_dataset.shuffle(buffer_size, seed = 100)\r\n",
        "    tf_dataset = tf_dataset.padded_batch(batch_size, padded_shapes=([-1], [-1], [-1], [-1], [-1], [-1]))\r\n",
        "    tf_dataset = tf_dataset.prefetch(buffer_size=AUTOTUNE)\r\n",
        "    return tf_dataset\r\n",
        "    \r\n",
        "def create_train_data(num_samples_to_train = config['num_examples_to_train'], shuffle=True, filter_off=False):\r\n",
        "\r\n",
        "    if config['use_tfds']:\r\n",
        "        examples, metadata = tfds.load(\r\n",
        "                                       config['tfds_name'], \r\n",
        "                                       with_info=True,\r\n",
        "                                       as_supervised=True, \r\n",
        "                                       data_dir=file_path['dataset'],\r\n",
        "                                       builder_kwargs={\"version\": \"3.1.0\"}\r\n",
        "                                      )\r\n",
        "        other_ds = 'validation' if 'validation' in examples else 'test'\r\n",
        "        train_examples = examples['train']\r\n",
        "        valid_examples = examples[other_ds]\r\n",
        "        \r\n",
        "        import json\r\n",
        "\r\n",
        "        metadata_2 = json.loads(metadata.as_json)\r\n",
        "\r\n",
        "        train_buffer_size = sum(map(int,metadata_2['splits'][0]['shardLengths']))\r\n",
        "        valid_buffer_size = sum(map(int,metadata_2['splits'][1]['shardLengths'])) + sum(map(int,metadata_2['splits'][2]['shardLengths']))\r\n",
        "    else:\r\n",
        "        doc, summ = create_dataframe(file_path.train_csv_path, num_samples_to_train)\r\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "                                                            doc, \r\n",
        "                                                            summ, \r\n",
        "                                                            test_size=config['test_size'], \r\n",
        "                                                            random_state=42\r\n",
        "                                                            )\r\n",
        "        train_examples = tf.data.Dataset.from_tensor_slices((X_train, y_train))\r\n",
        "        valid_examples = tf.data.Dataset.from_tensor_slices((X_test, y_test))\r\n",
        "        train_buffer_size = len(X_train) \r\n",
        "        valid_buffer_size = len(X_test)\r\n",
        "    train_dataset = map_batch_shuffle(\r\n",
        "                                     train_examples, \r\n",
        "                                     train_buffer_size, \r\n",
        "                                     split = 'train',\r\n",
        "                                     shuffle = shuffle,\r\n",
        "                                     batch_size=h_parms['batch_size'],\r\n",
        "                                     filter_off=filter_off\r\n",
        "                                     )\r\n",
        "    valid_dataset = map_batch_shuffle(\r\n",
        "                                     valid_examples, \r\n",
        "                                     valid_buffer_size, \r\n",
        "                                     split='valid',\r\n",
        "                                     batch_size=h_parms['validation_batch_size'],\r\n",
        "                                     filter_off=filter_off\r\n",
        "                                     )\r\n",
        "    log.info('Train and Test tf_datasets created')\r\n",
        "    return (train_dataset, valid_dataset, train_buffer_size, valid_buffer_size)\r\n",
        "    \r\n",
        "def infer_data_from_df(num_of_infer_examples=config['num_examples_to_infer']):\r\n",
        "    doc, summ = create_dataframe(file_path['infer_csv_path'], num_of_infer_examples)\r\n",
        "    infer_examples = tf.data.Dataset.from_tensor_slices((doc, summ))\r\n",
        "    infer_buffer_size = len(doc)\r\n",
        "    infer_dataset = map_batch_shuffle(\r\n",
        "                                      infer_examples, \r\n",
        "                                      infer_buffer_size, \r\n",
        "                                      split = 'infer',\r\n",
        "                                      batch_size=1              \r\n",
        "                                      )\r\n",
        "    log.info('infer tf_dataset created')\r\n",
        "    return infer_dataset"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "5383faa4ec554dc59c34be02a9bd6edd",
            "667efa312a014b2dbc738089f6e72cf8",
            "d7a1148a74a1462d92143d32bf5454b6",
            "126a92be2f2547d2b646d79d7949da4d",
            "3476b959f292498685ad05a48372532f",
            "8f6e7b1a44864485b0b2d2f00b1db729",
            "e104a552657e4363be4db85046bba639",
            "6ce29b08b64541648d352d117191139c"
          ]
        },
        "id": "j4CC_8ocZUH6",
        "outputId": "3f726a26-6118-46b3-bc34-fbccc309c092"
      },
      "source": [
        "import pandas as pd\r\n",
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "model = AbstractiveSummarization(\r\n",
        "                                num_layers=config['num_layers'], \r\n",
        "                                d_model=config['d_model'], \r\n",
        "                                num_heads=config['num_heads'], \r\n",
        "                                dff=config['dff'], \r\n",
        "                                vocab_size=config['input_vocab_size'],\r\n",
        "                                output_seq_len=config['summ_length'], \r\n",
        "                                rate=h_parms['dropout_rate']\r\n",
        "                                )\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "\r\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'log' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-35-d7c654e16889>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model = AbstractiveSummarization(\n\u001b[0m\u001b[0;32m      5\u001b[0m                                 \u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 \u001b[0md_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'd_model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-32-3f29b42d809a>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_layers, d_model, num_heads, dff, vocab_size, output_seq_len, rate)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_seq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_seq_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0membedding_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_embedding_from_bert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         self.embedding = tf.keras.layers.Embedding(\n\u001b[0;32m     62\u001b[0m                                                     \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-32-3f29b42d809a>\u001b[0m in \u001b[0;36m_embedding_from_bert\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_embedding_from_bert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m   \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extracting pretrained word embeddings weights from BERT\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m   \u001b[0mvocab_of_BERT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m   \u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab_of_BERT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'log' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcwT_AxtvGkO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952,
          "referenced_widgets": [
            "f00a6a57e5b948ba848cab5166f4f2dd",
            "0872e34b66f84af199feebe7849332a1",
            "09180cfa47b94eee937d299e916b3dab",
            "458fa919d1464af6b581d39d518bcda8",
            "c261e458b67540868f0c620b8ccbcccb",
            "ff6828c794e341f4bc50d6634ae14450",
            "f87a4f82dd5b41c68ab96981cb35dac1",
            "c90977e1741b418da92d1801db975591",
            "281518474371424e875f331014302374",
            "9e4c9973213d4f95ad700a9a5510bba1",
            "8a3ca4f488f948dbbe76bf092c39361c",
            "07ffe8376cb94d83ae4e50682a257206",
            "0700b07436874fcdb976cbd507a9109c",
            "8d411ae76b644292855437dbea7f425d",
            "b30a6f466c1d4fd3aef50bdfdcfcf36f",
            "b09d6fa1e100482a818eb9853f93b04a",
            "dafd58b314254a36b335854bd64b4128",
            "5803ef3bda8a4cad9bc05bad0267a366",
            "d9d8f1474a764d889fb287fe35cbea9e",
            "ceb64df82bd94558856fbf31fa478b61",
            "750fca7237684e29ac99a0a9d5f89c30",
            "34c4a51ef1534d54be7f9a549943f3e5",
            "1cd7196efbb14ddcb139d58aa8809154",
            "ac70bf2ceb5e45c290830a9d8be020e0",
            "c85ef6dd4dc44b29a84385dc3f755831",
            "ad758a57b829467397b753ad22b49524",
            "47bd0a8ff8ff42d39b613fe6c205c19f",
            "86ccfa06cd004661a4390a4d8d2c515c",
            "a4180ddd1f7c4f48b34a1892f8531a8a",
            "3c2ec00085f2476c886510cc883112ad",
            "9ea4c1cd9385456a96141469c1e9af87",
            "409c2105b7ad491aa8aefed7fe885646",
            "7dfcf5e11d2a4713a6cd6e439b31610d",
            "81887921e0c54f1d9c5093f13e3c0f56",
            "310d658613704286ae6dcb18f9720249",
            "e5a8a759c1264c6f8738c0cd9efc0006",
            "0eb7a1e7b97f432cb02765a011005144",
            "b93aa14b35264833bdaaa26fd8ac4e23",
            "7d9e05f63b62432da132669f2f23261d",
            "4e031ed028b84bb78f504a7f93a72d98",
            "a21fb4bb66224e64a2a21018f2523d62",
            "d593271dbd3a42dc9ae38c213b3ff7f3",
            "8031632b6a1947739c37d6c53c5918a5",
            "c23fd5968fc74310a6720924cb230d03",
            "fe1ce20396d14029be86dc2fc3593c27",
            "106576568c1748d0b1cabfa7696465a6",
            "57afa32e925e4101859609c6e4b9ad31",
            "be2c16068969410fa8f86a7b6426e9a7",
            "3f61c55b35514d569d64b5e4c159329e",
            "cfa9f9bb08094f2c813a323a5a8a2f6d",
            "7b8beabb49464ef796318f8b561a2424",
            "988c96adf51e473698c5d78a7c4fd4b3",
            "7b5393795fbf452f92934c2e6b3647cc",
            "ca2d1b168d5f4da8857743edc2811874",
            "d1616c50a2054fc78b4f164410f4ee80",
            "a9435e7348e046c09ff43aaa70f1d858",
            "38f2ae81e09b4dbb9051bce7db29322c",
            "07f498909b2449adb13cf556cbd196b4",
            "d04d8b716775499c980a1e569f87beed",
            "82f073e8391040a59f9853d0f553f908",
            "88e334563db54f2caa33071bd95e9180",
            "f72891ef50c74cbc81ef68f32ba14fab",
            "282655ddf19a4fa9b2603cc99ecea0a3",
            "18202ec720d542a187a978018a8d008f",
            "b97a1caa82fd43f6940ece471f3a354a",
            "02d236d5c5504d55aeda650dfb521b0c",
            "1d11ae8d2c344f19a42b103c47bd0708",
            "d5b31c0a42444fb8bde44d65f7364dbe",
            "298870dfaa7445609eb49b803bceb301",
            "eee8bb29437c48939c257bb793af6104",
            "45ae5fb4f3254243b5fc304d7843c461",
            "3aedfc1ed22f4c138f262c371b43a93b",
            "a6b7a7400ff24db8be922193c9667ebe",
            "ae4a5dcfa5b144649477289fff9a70e0",
            "c846ad445b69487c896d78a67debe7fb",
            "f25e172fcc2e41d38ab58ee19516aed1",
            "857edb26a68649948526b4188eb7ff05",
            "cb9f3a2a5c234567b7ed4fd07980bfa3",
            "ed5070632b8147dba5513d90e36ed8e7",
            "87611510dfa04d79bb269cfd0251e407"
          ]
        },
        "id": "5BaFBGrBYRhG",
        "outputId": "f0f289c9-9e1d-4a11-9d52-0cc53489ce2e"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "tf.random.set_seed(100)\r\n",
        "import time\r\n",
        "\r\n",
        "train_dataset, val_dataset, num_of_train_examples, _ = create_train_data()\r\n",
        "train_loss, train_accuracy = get_loss_and_accuracy()\r\n",
        "validation_loss, validation_accuracy = get_loss_and_accuracy()\r\n",
        "accumulators = []\r\n",
        "@tf.function(input_signature=train_step_signature)\r\n",
        "def train_step(input_ids, \r\n",
        "               input_mask, \r\n",
        "               input_segment_ids, \r\n",
        "               target_ids_, \r\n",
        "               target_mask, \r\n",
        "               target_segment_ids, \r\n",
        "               target_ids, \r\n",
        "               mask, \r\n",
        "               grad_accum_flag):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    (draft_predictions, draft_attention_weights, \r\n",
        "      refine_predictions, refine_attention_weights) = model(\r\n",
        "                                                           input_ids, input_mask, input_segment_ids, \r\n",
        "                                                           target_ids_, target_mask, target_segment_ids, \r\n",
        "                                                           True\r\n",
        "                                                           )\r\n",
        "    train_variables = model.trainable_variables\r\n",
        "    draft_summary_loss = loss_function(target_ids[:, 1:, :], draft_predictions, mask)\r\n",
        "    refine_summary_loss = loss_function(target_ids[:, :-1, :], refine_predictions, mask)\r\n",
        "    loss = draft_summary_loss + refine_summary_loss\r\n",
        "    #loss = optimizer.get_scaled_loss(loss)\r\n",
        "  gradients  = tape.gradient(loss, train_variables)\r\n",
        "  #gradients = optimizer.get_unscaled_gradients(gradients)\r\n",
        "  # Initialize the shadow variables with same type as the gradients \r\n",
        "  if not accumulators:\r\n",
        "    for tv in gradients:\r\n",
        "      accumulators.append(tf.Variable(tf.zeros_like(tv), trainable=False))\r\n",
        "  # accmulate the gradients to the shadow variables\r\n",
        "  for (accumulator, grad) in zip(accumulators, gradients):\r\n",
        "    accumulator.assign_add(grad)\r\n",
        "  # apply the gradients and reset them to zero if the flag is true\r\n",
        "  if grad_accum_flag:\r\n",
        "    for accumlator in accumulators:\r\n",
        "      accumulator.assign(tf.math.divide(accumulator,h_parms.accumulation_steps))\r\n",
        "    optimizer.apply_gradients(zip(accumulators, train_variables))\r\n",
        "    for accumulator in (accumulators):\r\n",
        "        accumulator.assign(tf.zeros_like(accumulator))\r\n",
        "  train_loss(loss)\r\n",
        "  train_accuracy(target_ids_[:, :-1], refine_predictions)  \r\n",
        "  \r\n",
        "@tf.function(input_signature=val_step_signature)\r\n",
        "def val_step(input_ids, \r\n",
        "             input_mask, \r\n",
        "             input_segment_ids, \r\n",
        "             target_ids_, \r\n",
        "             target_mask, \r\n",
        "             target_segment_ids, \r\n",
        "             target_ids, \r\n",
        "             mask, \r\n",
        "             epoch, \r\n",
        "             create_summ):\r\n",
        "  (draft_predictions, draft_attention_weights, \r\n",
        "   refine_predictions, refine_attention_weights) = model(\r\n",
        "                                                         input_ids, input_mask, input_segment_ids, \r\n",
        "                                                         target_ids_, target_mask, target_segment_ids, \r\n",
        "                                                         False\r\n",
        "                                                         )\r\n",
        "  draft_summary_loss = loss_function(target_ids[:, 1:, :], draft_predictions, mask)\r\n",
        "  refine_summary_loss = loss_function(target_ids[:, :-1, :], refine_predictions, mask)\r\n",
        "  loss = draft_summary_loss + refine_summary_loss\r\n",
        "  validation_loss(loss)\r\n",
        "  validation_accuracy(target_ids_[:, :-1], refine_predictions)  \r\n",
        "  if create_summ: \r\n",
        "    rouge, bert = tf_write_summary(target_ids_[:, :-1], refine_predictions, epoch)  \r\n",
        "  else: \r\n",
        "    rouge, bert = (1.0, 1.0)  \r\n",
        "  return (rouge, bert)\r\n",
        "  \r\n",
        "def check_ckpt(checkpoint_path):\r\n",
        "    ckpt = tf.train.Checkpoint(\r\n",
        "                               model=model,\r\n",
        "                               optimizer=optimizer\r\n",
        "                              )\r\n",
        "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\r\n",
        "    if tf.train.latest_checkpoint(checkpoint_path):\r\n",
        "      ckpt.restore(ckpt_manager.latest_checkpoint)\r\n",
        "      log.info(ckpt_manager.latest_checkpoint +' restored')\r\n",
        "      latest_ckpt = int(ckpt_manager.latest_checkpoint[-2:])\r\n",
        "    else:\r\n",
        "        latest_ckpt=0\r\n",
        "        log.info('Training from scratch')\r\n",
        "    return (ckpt_manager, latest_ckpt)\r\n",
        "\r\n",
        "# if a checkpoint exists, restore the latest checkpoint.\r\n",
        "ck_pt_mgr, latest_ckpt = check_ckpt(file_path['ckpt_path'])\r\n",
        "for epoch in range(h_parms['epochs']):\r\n",
        "  start = time.time()  \r\n",
        "  train_loss.reset_states()\r\n",
        "  train_accuracy.reset_states()\r\n",
        "  validation_loss.reset_states()\r\n",
        "  validation_accuracy.reset_states()\r\n",
        "  print(\"Start of epoch\", epoch+1)\r\n",
        "  for (batch, (input_ids, input_mask, input_segment_ids, target_ids_, target_mask, target_segment_ids)) in enumerate(train_dataset):\r\n",
        "  # the target is shifted right during training hence its shape is subtracted by 1\r\n",
        "  # not able to do this inside tf.function since it doesn't allow this operation\r\n",
        "    if batch > config['start_from_batch']:\r\n",
        "      mask = tf.math.logical_not(tf.math.equal(target_ids_[:, 1:], 0))\r\n",
        "      target_ids = label_smoothing(tf.one_hot(target_ids_, depth=config['input_vocab_size']))\r\n",
        "      grad_accum_flag = True if (batch+1)%h_parms['accumulation_steps'] == 0 else False\r\n",
        "      train_step(\r\n",
        "                 input_ids, \r\n",
        "                 input_mask, \r\n",
        "                 input_segment_ids, \r\n",
        "                 target_ids_, \r\n",
        "                 target_mask, \r\n",
        "                 target_segment_ids, \r\n",
        "                 target_ids, \r\n",
        "                 mask, \r\n",
        "                 grad_accum_flag\r\n",
        "                 )\r\n",
        "      batch_run_check(\r\n",
        "                      batch, \r\n",
        "                      epoch, \r\n",
        "                      start, \r\n",
        "                      train_summary_writer, \r\n",
        "                      train_loss.result(), \r\n",
        "                      train_accuracy.result(), \r\n",
        "                      model\r\n",
        "                      )\r\n",
        "      \r\n",
        "      predicted = (tokenizer.decode([i for i in tf.squeeze(tf.argmax(refine_predictions,axis=-1)) if i not in [101,102,0]]))\r\n",
        "      target = (tokenizer.decode([i for i in tf.squeeze(target_x) if i not in [101,102,0]]))\r\n",
        "      print(f'the golden summary is {target}')\r\n",
        "      print(f'the predicted summary is {predicted if predicted else \"EMPTY\"}')\r\n",
        "      ckpt_save_path = ck_pt_mgr.save()\r\n",
        "      (val_acc, val_loss, rouge_score, bert_score) = calc_validation_loss(\r\n",
        "                                                                          val_dataset, \r\n",
        "                                                                          step+1, \r\n",
        "                                                                          val_step, \r\n",
        "                                                                          valid_summary_writer, \r\n",
        "                                                                          validation_loss, \r\n",
        "                                                                          validation_accuracy\r\n",
        "                                                                          )\r\n",
        "      \r\n",
        "      latest_ckpt+=epoch\r\n",
        "      log.info(\r\n",
        "              model_metrics.format(\r\n",
        "                                    step+1, \r\n",
        "                                    train_loss.result(), \r\n",
        "                                    train_accuracy.result(),\r\n",
        "                                    val_loss, \r\n",
        "                                    val_acc,\r\n",
        "                                    rouge_score, \r\n",
        "                                    bert_score\r\n",
        "                                  )\r\n",
        "              )\r\n",
        "      log.info(evaluation_step.format(step+1, time.time() - start))\r\n",
        "      log.info(checkpoint_details.format(step+1, ckpt_save_path))\r\n",
        "      if not monitor_run(\r\n",
        "                        latest_ckpt, \r\n",
        "                        ckpt_save_path, \r\n",
        "                        val_loss, \r\n",
        "                        val_acc, \r\n",
        "                        bert_score, \r\n",
        "                        rouge_score, \r\n",
        "                        valid_summary_writer, \r\n",
        "                        step+1):\r\n",
        "        break  \r\n",
        "      \r\n",
        "  print(\"End of epoch\", epoch+1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Load dataset info from d:\\LearningML\\abstractive_summarization\\input_files\\cnn_dailymail\\cnn_dailymail\\3.1.0\n",
            "INFO:absl:Reusing dataset cnn_dailymail (d:\\LearningML\\abstractive_summarization\\input_files\\cnn_dailymail\\cnn_dailymail\\3.1.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split None, from d:\\LearningML\\abstractive_summarization\\input_files\\cnn_dailymail\\cnn_dailymail\\3.1.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-36-6b51e9aac1b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_train_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_loss_and_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_loss_and_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-34-11517b21b4b6>\u001b[0m in \u001b[0;36mcreate_train_data\u001b[1;34m(num_samples_to_train, shuffle, filter_off)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mtrain_buffer_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mvalid_buffer_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     train_dataset = map_batch_shuffle(\n\u001b[0m\u001b[0;32m    163\u001b[0m                                      \u001b[0mtrain_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                                      \u001b[0mtrain_buffer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-34-11517b21b4b6>\u001b[0m in \u001b[0;36mmap_batch_shuffle\u001b[1;34m(dataset, buffer_size, split, shuffle, batch_size, filter_off)\u001b[0m\n\u001b[0;32m    114\u001b[0m     tf_dataset = dataset.map(\n\u001b[0;32m    115\u001b[0m                             tf_encode(\n\u001b[1;32m--> 116\u001b[1;33m                                 \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                                 \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'doc_length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                                 \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summ_length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}